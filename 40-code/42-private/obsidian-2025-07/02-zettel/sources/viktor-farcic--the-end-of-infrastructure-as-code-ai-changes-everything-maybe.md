---
global-template: source
source-title: "The End of Infrastructure-as-Code: AI Changes Everything... Maybe..."
source-url: https://youtu.be/xwDQh3gAec0
source-platform: youtube
source-type: video
source-creators: [["Viktor Farcic"]]
source-published-date: 2025-07-21
source-fetched-date: 2025-10-05
source-length-minutes: 27
topics: [infrastructure-as-code, ai-agents, devops, kubernetes, terraform, automation]
source-status: drafted
---

# AI notes

## TLDR
- Infrastructure-as-Code tools like Terraform and Pulumi are designed for human cognitive limitations and may become obsolete as AI agents can interact directly with APIs without needing user-friendly abstractions.
- Historical patterns show that each generation of infrastructure tools fails to adapt to paradigm shifts, from on-prem to cloud to Kubernetes, and AI represents the next major transformation.
- AI agents will operate autonomously, making real-time decisions and learning from mistakes, rendering current tools that rely on declarative YAML and static configurations inadequate.
- The future belongs to tools built specifically for AI agents rather than forcing AI to use human-centric formats like HCL, YAML, or CRDs.
- Vendors must either evolve radically or risk their products becoming irrelevant, as AI-first operations will bypass traditional infrastructure management approaches.

## Key ideas
- APIs are the foundation of all infrastructure management, but humans need abstractions like Terraform to simplify complex API interactions, while AI agents don't share these limitations.
- Kubernetes controllers exhibit AI-like behavior through continuous reconciliation and drift detection, but AI agents will go further with nondeterministic, learning-based operations.
- Every major shift in infrastructure paradigms (on-prem → cloud → Kubernetes) has killed previous generation tools because they couldn't adapt to new operational models.
- AI agents will communicate directly with provider APIs rather than using intermediary formats designed for human readability, making tools like Terraform unnecessary.
- The key to surviving the AI revolution is building agent-native interfaces and abandoning human-centric paradigms, not trying to fit AI into existing tools.

## Detailed Summary
- **API Foundation**: All infrastructure management ultimately relies on provider APIs (AWS, Azure, Kubernetes, etc.), regardless of whether humans interact directly or through tools.
- **Human-Centric Tools**: Infrastructure-as-Code tools like Terraform and Pulumi exist because humans get overwhelmed by complex JSON payloads and API calls; they provide cognitive shortcuts through formats like HCL and YAML.
- **Kubernetes Revolution**: Kubernetes introduced controller-driven reconciliation and drift detection, allowing operators to manage state continuously, similar to how AI agents will operate.
- **Pattern of Tool Death**: Historical analysis shows tools fail to adapt to paradigm shifts - Chef/Puppet/Ansible couldn't transition to cloud, Terraform/Pulumi struggle with Kubernetes-native approaches.
- **AI Today**: Current AI usage is limited to supervised code generation and suggestions, but autonomous agents capable of learning from mistakes and operating unsupervised are imminent.
- **AI Revolution**: AI agents will bypass human-centric abstractions, communicating directly with APIs and making dynamic decisions, rendering current tools obsolete unless they evolve into agent-native interfaces.

### Key quotes
- "Infrastructure-as-Code tools like Terraform and Pulumi have revolutionized how we manage cloud and Kubernetes resources, yet their days may be numbered. AI agents, capable of handling complexity without the cognitive limitations of humans, don't need the same abstractions we've built our industry around."
- "AI agents don't operate like humans. They don't get overwhelmed by complexity in the same way we do. They don't need user-friendly abstractions, and that changes everything."
- "Every single generation of infrastructure tools had died when the industry shifted and the pattern is always always the same."
- "We know that there is an API on the other end and we know that Terraform, Pulumi, Crossplane compositions, and other tools and formats are converting user-friendly formats to API requests. Does the AI need those same formats? Can't it go directly to the API and make requests?"
- "The tools that survive the AI revolution won't be the ones that try to make AI fit their existing paradigms. They will be the ones that completely reimagine themselves for the AI first world."

---

## Source notes

### Source Metadata

- **Video ID**: xwDQh3gAec0
- **Channel**: DevOps & AI Toolkit
- **Channel URL**: https://www.youtube.com/channel/UCfz8x0lVzJpb_dgWm9kPVrw
- **Duration**: 00:27:03 (1623 seconds)
- **View Count**: 27130
- **Like Count**: 850
- **Tags**: AI, AI Agents, API Integration, APIs, Ansible, ArgoCD, Automation, CRD, Chef, Cloud Computing, Cloud-Native, Configuration Management, Crossplane, Declarative Infrastructure, DevOps, Flux, GitOps, HCL, Immutable Infrastructure, Infrastructure Automation, Infrastructure-as-Code, JSON, Kubernetes, Kubernetes Controllers, Platform Engineering, Pulumi, Puppet, Software Engineering, Terraform, YAML
- **Categories**: Science & Technology

### Source Description

Infrastructure-as-Code tools like Terraform and Pulumi have revolutionized how we manage cloud and Kubernetes resources, yet their days may be numbered. AI agents, capable of handling complexity without the cognitive limitations of humans, don't need the same abstractions we've built our industry around. This video examines how API-driven infrastructure has led to tools designed for human convenience and why the rise of AI agents will render these tools obsolete.

Discover how each generation of infrastructure tools, from Chef and Puppet to Terraform and Crossplane, failed to adapt to paradigm shifts, and why AI agents represent the next big transformation. Will today's industry leaders adapt to AI-first operations, or will they repeat the mistakes of history by clinging to outdated paradigms? The AI revolution is coming, and the future belongs to those bold enough to rethink everything.

#InfrastructureAsCode #AI #DevOps

---

## Raw source

Here's something that might shock you. Every infrastructures code tool you're using today will be dead in upcoming years. Terapform, Palumi, all of them. And the killer AI agents that don't need the abstractions we've built our entire industry around. Now, I know this sounds crazy. You're probably thinking, "Hey, but we just invested years learning those tools." Here's the thing, though. AI agents don't operate like humans. They don't get overwhelmed by complexity in the same way we do. They don't need user-friendly abstractions, and that changes everything. By the end of this video, you will see exactly why the tools we consider essential today are actually obstacles for AI agents and what's coming to replace them. But first, let me show you how we got here where we are.

Long, long time ago, long time ago, providers of services realized that the only reasonable way for us to interact with what they offer is through HTTP APIs. Since then everyone and I repeat everyone offers services through APIs that can be AWS, Azugu, cloud, upcloud, Lenode or anyone else or anything else. We can get anything we need through API of the provider. Even if we do not use public platforms, but we do everything ourselves in our own on-prem data centers, everything is still available through an API. How do we get the new VM managed by vSphere API? How do we deploy our application to a Kubernetes cluster? API. If you happen to work in a company where there are no APIs to manage whatever you're managing, I have an important advice for you. Run. Turn around. Get out of the office you're in and never look back. Go somewhere else. But here's where it gets interesting, and this is key to understanding why everything is about to change. It does not matter whether we interact with them directly or indirectly. It does not matter whether we interact with them directly or through a graphical user interface or through a terminal CLI or through GitHubs. It's always API and the question is only whether we interact with it directly or indirectly. So the flow is human that's you request something directly by interacting with the provider's API or to be more precise with something as simple as URL. Almost no one is doing that. Nobody interacts with AWS or Kubernetes or anything else with C URL. As a matter of fact, C URL might be the most efficient way to interact with API yet we do not want to use it. Why? This is where the story gets really interesting. Why don't we do that, the answer is simple and it reveals something crucial about the coming AI revolution. There are formats and tools that make it much easier to define what we want than to communicate with the API of the provider we're using. That's where Terraform, Palumi, and others jump in. But here's what nobody talks about. Those tools were designed for human limitations.

Terraform and other tools often called infrastructure is code have a very simple primary function. They help us define what we want in a user-friendly way. Their primary function is to transform HCL or YAML or some other format into API requests very similar to what we would do with C URL. That's what they do. So we change the flow by adding something like HTL in between us and sending requests to APIs. We write HCL or YAML or whatever we feel comfortable with and those tools like Terraform and Pulumi translate that into API request similar to what we would do with CURL and send them to API. Now I know that those tools do more than what I described but that's still their primary or main purpose. They provide a userfriendly way for us to define what we want and translate that into API requests. But here's the key insight. User friendly means designed for human cognitive limitations. We get overwhelmed by complex JSON payloads. We make mistakes with intricate API calls. We need abstractions that reduce mental load. We require readable formats that we can understand, debug, and maintain. Those tools exist because humans are bad at complexity. We need simplification. We need cognitive shortcuts. We need tools that make something complex simple. And then we evolved further by coming up with state management. But wait, this is where things get really interesting.

Kubernetes still does the same basic operations as what we were doing before adopting it. We define what we need this time in YAML and we use cube control as intermediary that will communicate to the API. What makes Kubernetes different is continuous drift detection and reconciliation. And this is where we start to see AI like behavior. Instead of performing operations right away, Kubernetes stores the desired state incds controllers figure out what to do and when to do it. And on top of that, it does all that continuously. Those controllers are running in a loop and ensuring that the actual state is the same as the desired state forever and ever. If you specified that we want three pods and one of them fails, it will create a new one. If you specify that we want to scale nodes of the cluster, whenever the usage reaches, let's say 80%, it will create new nodes and so on and so forth. The major difference between the era before Kubernetes and where we are now is that operators inside the cluster, the controllers, took over a big part of the work we humans are doing. But we went further than that though and this is where it gets crazy. Now our Kubernetes clusters are interacting with APIs outside the cluster. Once something reaches Kubernetes API controllers might be transforming our requests into requests sent to provider APIs be it AWS or Azure or Google Cloud or anything else. And that is awesome since we can leverage Kubernetes controllers to do a much wider range of operations we had to do ourselves in the past. They can monitor the state of a database in Azure and fix issues caused by drifts between the desired and the actual state. They can manage Lambda functions in AWS. They can be in charge of a fleet of clusters in Google. Kubernetes controllers or operators are doing the work we had to do in the past. And here's the breakthrough insight. That's where we can see similarities between Kubernetes controllers and AI agents.

Okay, so here's what nobody talks about and this is crucial to understanding what's coming next. Every single generation of infrastructure tools had died when the industry shifted and the pattern is always always the same. Remember Chef Papet and Anible? Those tools were kings of the on premises world. They managed server configurations, deployed applications and automated infrastructure tasks. Everyone used them. They were the right way to manage infrastructure. Then the cloud happened. Suddenly we weren't managing static servers anymore. We were spinning up and tearing down infrastructure dynamically. We needed to create databases, load balancers and networks on demand. Did chef adopt? Did puppet build? Did anible transform into cloud native tools? No. They tried. They added cloud modules and plugins, but they were fundamentally designed for a different world. They were built for persistent service not ephemeral infrastructure. They failed to make the transition. Enter Terraform Palumbi and cloud formation. Those tools were born for the cloud. They understand immutable infrastructure. They could create and destroy resources. They were the new kings. New kings. But then Kubernetes happened. Suddenly we weren't just managing cloud resources. We were managing resources through Kubernetes. We wanted everything to be a CRD. We wanted controllers to manage state. We wanted GitHubs workflows. Are Terraform and Palumi adopting? Are they becoming Kubernetes native? They're trying, but they're struggling. Terraform has Kubernetes providers, but they are clunky. Palumi has Kubernetes support, but it feels forced. Those tools were designed for direct API calls, not for controllerdriven reconciliation. And now we have crossplane, Argo City, Flux, and custom controllers. Those tools understand Kubernetes. They work through CRDs and controllers. They embrace continuous reconciliation. But guess what's coming next? I mean, you know it. It's CIA agents. And here's the pattern. Every generation fails to adapt to the next thing, whatever is coming. Why? Because they're fundamentally designed for the previous world, for the previous way of working. They cannot just add features. They need to be completely reimagined. The tools that dominated one era became obstacles in the next. And the vendors well they cannot let go. They keep trying to force their existing tools into new way of working instead of accepting that their tools have become obsolete.

Now this isn't speculation. This is history repeating itself and it's about to happen again. But who knows maybe it doesn't have to. Here's what I hope will be different this time. I hope that Kubernetes native tool vendors will learn from history. I hope they will look at what happened to Chef, Papet and Anible when the cloud arrived and I hope that they will see how terapon and Palumi are struggling to adapt to Kubernetes and I hope that they will make a different choice instead of trying to force AI agents to use YAML manifests and CRDs. Maybe they will ask, hey, what do AI agents actually need? Instead of building AI assistants that help humans write Kubernetes configs, maybe they will build agent native interfaces. Maybe maybe crossplane will evolve beyond compositions. Maybe Argo City will transform beyond GitHubs. Maybe the Kubernetes ecosystem will embrace AI agents instead of fighting them. But that requires something that is historically rare. The willingness to abandon what made you successful. The courage to kill your own products before someone else does. The vision to see that adaptation sometimes means complete transformation. Will they do it? Well, history says no. But I hope that this time will be different. I hope that Kubernet will be the first to successfully evolve instead of dying. Time will tell.

Now we're at the beginning of the AI era. Instead of writing that YAML ourselves, we can tell AI agents to do it for us. We are using AI to help us write stuff that we were writing ourselves in the past. That stuff can be YAML or HCL or backend code in Go or front end application in Typescript or anything else. From there on the process is still the same. In case of resource management, that could be Kubernetes. That over there is on the first look very similar to what we do with Kubernetes controllers. If you define AI agents as processes that perform operations on our behalf, we can easily come to the conclusion that Kubernetes controllers fit that same description. In both cases, we define what we want and they do it. An AI agent might write code based on our input. It might analyze a problem inside one of the clusters and suggest a fix or fix it directly. Similarly, Kubernetes controllers also take our input the desired state and make it happen. They ensure that whatever we specified is what is running. But here's where everything changes. Kubernetes is declarative and explicit. It will create and manage exactly what we tell it we want. We need to be precise or to be more specific, the desired state we define needs to be precise. We cannot instruct Kubernetes to run an application. We need to define a deployment and inside that definition we need to specify which specific container image it should use, how many replicas it should manage and we can do many other things and we have to do many other things. We can specify ranges though we can say hey run between three and seven replicas depending on the memory consumption but that's still more or less very very specific. AI is not like that at least not today. It is not specific. It is nondeterministic. If you say generate application manifest and make sure that image is used and that number of replicas it will have, it will do that for us. However, multiple executions of the same prompt will produce different results. It is nondeterministic. Do you know of other examples of nondeterministic behavior? H well, it's us humans. We are also nondeterministic. Two people tasked to perform the same operation will end up producing different results. Heck, the same person is unlikely to produce the same outcomes when tasked to do the same thing twice. That nondeterministic nature of both AI and humans is important and we'll get back to it later because it's about to become AI's greatest strength most likely. For now, the important note is that the usage of AI through agents today is mostly limited on us instructing them to give us some information or to generate something. We use them to generate code or to write YAML manifests or something similar. Even when we do let them perform operations, we do that only in supervised mode. Agents suggest what they will do, we review those suggestions and we allow or deny them to do whatever they wanted to do. All in all, today we use AI to generate stuff we would normally generate ourselves. We trust Kubernetes to perform unsupervised operations because those operations are deterministic. We do not trust AI agents to do the same and that will change very soon and when it does everything we built becomes obsolete.

The problem is that we see AI agents as complimentary to humans. And that's about to be our biggest mistake. A developer will use an agent to write code. Most of the time, at least when serious development is concerned, that developer will supervise the agent. It will tell it when it did something wrong. It will lead it when it goes astray. Similarly, someone called DevOps engineer, which is a silly name to begin with, or simply ops or a platform engineer or something similar, will instruct the agent to generate some other code, including YAML or HCL. Today, we might go as far as to use agents to tell us what's wrong with the live system and maybe even to suggest a fix, but not to fix it. Today agents are supervised by people in specific roles. In our industry, those people are software engineers. And here it goes. Soon the supervision part will be mostly gone. We will instruct agents to do something and they will do it. We'll ask an agent to fix an issue in code and it will fix it and it will create a pull request and it will review it and it will merge it to the main branch and it will deploy to production. Similarly, we might ask an agent to create and manage database or a cluster or some other types of resources. That day is not today but it will come. It will come very soon. Hence the future flow will be from a human asking the agent to do something and that agent doing whatever needs to be done. So how will it do what needs to be done? The answer to that question is the same as how we were doing it so far. if we use APIs of the providers be it Kubernetes or AWS or Azure or Google cloud or vSphere or anything else. So what is missing for that to happen? What is missing that will make agents autonomous? Now to be clear, there are a lot of things missing but I'll focus on two which I believe are the most important. First, agents need to develop capability to learn. Just as we humans are learning, bad things will happen. There will be suboptimal or even disastrous outcomes with agents just as there are similar outcomes with humans. Making a mistake is normal. Repeating the same mistake is stupid. We're on a brink of having learning agents or learning models that will learn from mistakes and by doing so stop repeating them. The second important piece of the puzzle is that it is missing memory. We already have solutions for agents to memorize roles and processes and whatever else needs to be memorized, but those are far from being reliable. We need to get better at that. A new hire will spend considerable time learning how the company operates, whether to work in separate branches or push directly to mainline, which languages and frameworks are used in applications, which tools are used to manage resources and so on and so forth. Similarly, all that internal knowledge needs to be passed to agents or models so that they can operate under the same rules. Actually, that over there is wrong. They should not operate under the same rules. We'll get to that later. What matters is that there must be rules followed by everyone. No matter whether we are talking about humans or AI agents, I have no doubt that we'll get those and other improvements we need. That's not my concern. at least not in this video. My big doubt is about tooling and formats and languages and this is where everything breaks.

Let's say that we want to instruct an agent to create a database. How would we do that? Natural reaction would be to instruct the agent to use the tools we are using, right? If for example we use Terraform, we would probably instruct the agent to create HTF files and then run Terraform apply. Right? I think that's wrong. I think we'll have a major shift in that area, mainly because we're trying to force AI to use tools designed to help us humans. Let's go back to that database example and think of the simplest way an AI agent would create it and manage it. Here's the breakthrough insight. We know that there is an API on the other end and we know that Terraform, Palumi, Crossplane compositions, and other tools and formats are converting user-friendly formats to API requests. Does the AI need those same formats? Can't it go directly to the API and make requests? What makes direct HTTP requests with JSON or some other payload any worse for agents than Terraform and other intermediary formats? H you remember what we established earlier? Our tools exist because humans are bad at complexity. We need cognitive shortcuts. We need readable formats. We need mental models that we can understand. AI agents don't have those limitations. They don't get overwhelmed by complex JSON. They don't make syntax errors in API calls. They don't need user-friendly obstructions. They can handle row complexity without breaking down or at least we think that they will be able to do it in not so distant future. We are used to abstractions because abstractions make our lives easier. AI probably does not need abstractions. As a matter of fact, abstractions will likely constrain it just as they constrain us. The major difference is that we get overwhelmed without abstractions. AI probably doesn't, or to be more precise, will not in the future. That being said, I'm sure that agents will need tools and specific formats, but those will be very different. Instead of trying to force them to use tools that help us, we should think of the tools that help those agents. What I'm trying to say is that agents will not need terraform or pulum or crossline compositions. They can talk directly to APIs and do what needs to be done. They can observe the state of what was done and react when the state changes. They are or they will be acting in the same way humans are acting. But they are not humans. So they do not need the same tools nor the same languages nor the same formats. Now you might say that's Those APIs are too complex. They might not be well doumented. They might not be the right interface for models and agents. You might be right. But if you are, the answer is still not Terraform or other tools. But as I already mentioned, tools designed specifically for agents. A good example is MCP or model context protocol. If you need something from AWS and for whatever reason direct communication to its API is not a good option, agents can hook into AWS MCP and do whatever needs to be done. Terraform is not the answer. It is a tool designed for us, not for agents and we should not try to fit it where it does not belong. Even if MCPS are not the answer, as I'm not sure that they are, there will be something else. And that's where the historical pattern becomes unavoidable. Just like Chef couldn't adapt to the cloud, just like Terraform is struggling to adapt to Kubernetes, Kubernetes tools will not adapt to AI models and agents. Why? Because Kubernetes controllers are designed for human defined desired state. They expect explicit YAML manifests. They work with static configurations. But AI agents will work dynamically. They will make uh real-time decisions. They will adapt and learn and change their approach based on context. Will crossplane adapt? Will Argo CD evolve? Will custom controllers transform? History says no. The pattern is clear. The tools that dominate one era become obstacles in the next and we are about to see it happen again. All that means that many of the tools we are using will eventually stop being useful. There is no logical need for Terraform or similar tools for operations performed by agents. Those will disappear or they will be transformed into something very different. They will die a slow and agonizing death and they will make everyone using them suffer. Instead of thinking how can AI do what we do using the same tools we find useful, we should focus on making tools that are useful to agents. Why would they write let's say HCL that is transformed to HTTP requests with JSON payload instead of making those same requests directly? Why would they use crossplane compositions designed to make cognitive load smaller for humans? We need to start thinking how we can enable those agents to do the right thing. We've been doing that with people for centuries and now is the time to rethink everything. I do not yet know what will be that final form. I do not have a clear idea how will those tools look like nor which formats will be most optimal for agents to do what they need to do. What I do know is that it will be very very different than what we use today. That means that tools like Terafon, Palumi and others will disappear or transform themselves into something very very different. The problem is that vendors behind those tools will likely not be able to let go. Most of them will not admit to themselves that what worked in the past will not work in the future. They will not recognize that the agents do not need them. Instead, most of them will keep pushing the ideas they have today. Those ideas can be summarized with we create agents that help us write stuff that humans are writing. If I'm Kashi Corp, I'm probably creating agents and models that help people write HCL and execute Terraform apply instead of trying to figure out how to enable agents to do what they need to do in the most efficient and reliable way. As such, most of the tools from the established vendors will eventually disappear and be replaced by those built from scratch to meet the new demand. Just as Chef couldn't transition from on-prem to cloud, just as Terraform is struggling to transition from cloud to Kubernetes, those available today will likely not be able to transform into the world operated by agents. Most of them won't. Most of them will not be needed and will slowly die. Five or 10 years from now, we will look at them with sentimental feelings similar to those we have for mainframe today. It's still in use somewhere, but most of us do not care for it. AI will kill most of infrastructures code tools. It's only a matter of time unless they choose to evolve. The tools that survive the AI revolution won't be the ones that try to make AI fit their existing paradigms. They will be the ones that completely reimagine themselves for the AI first world. They will ask the hard questions like what if we abandoned YAML entirely? What if we built agent native APIs from scratch? What if we killed our current products to build something radically different? The companies that make this transition won't just survive. They will dominate the next era. But it requires something most vendors struggle with. The courage to destroy what made them successful so they can build things that will make them essential. History shows us the patterns, but history doesn't have to repeat if we choose to learn from it. The choice is theirs and the clock is ticking. Thank you for watching. See you in the next one. Cheers.