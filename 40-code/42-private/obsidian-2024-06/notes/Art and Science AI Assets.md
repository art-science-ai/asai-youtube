Assets for podcast and newsletter
# Show assets

### Newsletter description
A podcast and newsletter about the science of how AI works and the art of how you can use AI to reimagine your life, business, and society. 

### Podcast description
A podcast about the science of how AI works and the art of using AI to reimagine your life, business, and society. 

Hosted by Nikhil Maddirala (AI Product Manager) and Piyush Agarwal (AI Sales Executive), bringing you their expertise from world‚Äôs leading AI companies.

### Links
ArtScienceAI.substack.com
youtube.com/@ArtScience-AI

## Brand
Colors
2E454B: Teal ("Art and")
B71D1D: Crimson ("AI")
F5ECCF: Beige (background)
618D8E: Cyan ("science of")
ACF2E5: Mint (painting background)

### Images
- Requirements
	- YT: 2048/1152 = 1.78
	- FB cover: 851/315 = 2.7
	- Linkedin cover: 5.91
	- Substack wordmark: 1344√ó256 = 5.25
	- Substack banner: 1100/220 = 5
- Fiverr
	- Linkedin cover: 1536/396 = 3.88
	- Twitter cover: 1500/500 = 3
	- 


# S1-E0: Introducing season 1: Piyush and Nikhil
## Notes
In this introductory episode of Art and Science of AI we discuss our background, expertise, and motivation for embarking on this journey to demystify AI! Piyush shares his fascination with seemingly magical AI technologies like ChatGPT and MidJourney, and his desire to understand the underlying mechanics. Nikhil shares his background in AI, and his plan for demystifying ChatGPT in this season: starting with the basics of Artificial Intelligence (AI) and Machine Learning (ML), we will demystify key concepts such as neural networks, deep learning, and Large Language Models (LLMs). We will also explore the exciting potential of ChatGPT and its implications for business and society. 

Note: Season 1 was originally recorded back in May 2023 as a continuous 3-hour long conversation. Season 2 is now live, so please subscribe for new episodes every week! artscienceai.substack.com

=== ‚è∞ CHAPTERS  ===
00:00: The Magic of ChatGPT and the motivation to demystify AI
04:45: Nikhil's background and expertise

=== üîó REFERENCES ===
Home page: artscienceai.substack.com
Nikhil Maddirala: https://www.linkedin.com/in/nikhilmaddirala/
Piyush Agarwal: https://www.linkedin.com/in/piyush5/


=== üí¨ KEYWORDS ===
```
#ChatGPT #AI #ML #ArtificialIntelligence #MachineLearning #LLM #tech #podcast
```


## Transcript
(00:00.046)
Welcome Nikhil to Docents. Thank you so much for doing this. Yeah. I'm so happy that we're doing this. Thank you for having me. I'm super excited. Yeah. So for those who are watching, I'll just give some context on what is it that we're doing exactly. Monica and I have a podcast called Docents. You obviously know that, but I'm going to act as if you don't know about it, just so that everyone also has context. So during our free time, we do this podcast where I'm like endlessly curious about like a lot of things in the world. Monica reads a lot.

And she basically explained those things to me. So like the structure of Docents is we have a podcast around this topic of big history. And the idea is like you have to start, if you have to start your educational learning, you have to start somewhere. And we started with big history, which basically explains like the history of everything. And like everything is a big word, right? Like, but it literally encompasses everything. So it starts from the big bang and.

right from Big Bang, which happened like 13 .8 billion years ago, how did it all come to here? Like we're living in Silicon Valley, which is like in some sense, which is like the peak of human civilization right now. So how did we come from atoms to like evolution? So like, that's the idea we have done about 23 episodes so far. And the general idea with those senses that she will in every episode, she will explain a topic to me. So recently,

I mean, we haven't recorded for a while, but recently I've just been so fascinated with all of the developments that's been happening around here. You and I have talked about it a lot. I mean, for also those of us listening that you and I are good friends, like we're the best of friends. We're childhood friends. We have known each other for the longest time. I feel like we have amazing conversations. So I invited you because you know this technology pretty well.

And the main goal is I just want to understand how it all works. So basically I'm Monica in this episode. You are Monica in this episode. Monica is taking care of our child right now. Which is the reason why you haven't recorded a podcast in a while. Exactly. Yeah. We had a baby girl which we're really happy about and it's been hard to record. Actually, another reason is that I'm hoping with this we'll get motivation to start recording again sometime soon. So yeah, you said right, you're Monica in this episode. And the simple idea is I've been...

(02:13.39)
playing around with chat GPT like almost everyone is around me, like this technology, which is sort of blown up around us. And it's not just chat GPT. It's like I've been playing around with mid journey and it almost seems like magic to me. Like when I, when I talk to chat, chat GPT, the way I think about this is it's as if I've talking to the smartest person I've ever talked to in my life. Like chat GPT knows everything about everything. And it's about to give me advice in a lot of things. Like for example,

This is probably not a good place to be seeking such advice, but I was like, my baby girl has turned six months old. I want to start feeding her solid food soon. Can you help me think through like, what are some considerations? Like the idea is I do a lot of these things. Can you help me think through? And it'll like come up with really good answers and it'll get me started. I've been playing around with mid -journey. I'll give it prompts and it comes up with such fascinating images. So to me, it just seems like magic. Like this is magic. Like I, I don't think I have been this

excited about any new technology. I remember the only time I was this fascinated by technology is when I first discovered the internet. I was like, whoa, I could just log into and get access to anything under the earth. So I really like the magic part, but I want to understand the trick behind the magic. So can you play the magician who spoils this trick for me? Can you give me a look under the hood? My goal from this is in our conversation, I want to really, really, really understand how this technology works. And I know it's...

It might be hard to do it in a conversation, but even if I can understand at a fundamental level what empowers all of these technologies, that would be a good win for me out of this conversation. That would be good. Yeah. So I think what I was hoping to cover is chat GPT is super exciting right now. There's a lot of possibility with chat GPT and language model powered applications.

But maybe we can take a step back and think about some of the fundamental building blocks of AI and machine learning. And that's something I can help with. And we can go deep into how does machine learning work? What are models? How are they trained? And then probably we won't be able to get into how is chat GPT trained. Maybe at a high level we can look at that. But we can build up some of the foundation of what models are, how they're trained, and build some intuition behind how a system like chat GPT works. That's amazing. That's actually.

(04:35.31)
The perfect reason why you're here is because I don't even know what I don't know. So like, I want to learn how chat jibbity works, but all of the things that you described, models, how they're training. I want to understand the basics of like, what is a model even? Like, what does it mean to train a model? Right? And because I don't know what I don't know, I don't know what are the things that I need to know. So you actually, I think put it right. I want to understand the fundamental building blocks of this technology that ultimately powers something like chat jibbity and

Maybe if I understand the fundamentals, I'll be able to appreciate this technology and also see like what are the other possibilities with this technology? What are some of its limitations? So yeah, like without much further ado, like why don't you take it away and help me understand like the building blocks of eventually what leads up to something like a chat GPT? Yeah, sure. So I think the I prepared like a couple of topics that I want to cover and let's keep it interactive. Like whenever we go through a topic, keep

asking me questions about it. I'll maybe give a brief introduction to what this topic is and you can keep asking me questions and we'll have an interactive back and forth. But what I was planning to cover is basically what is artificial intelligence? What is machine learning, which is a specific subset of artificial intelligence? And then another subset of that is deep learning and neural networks and we'll cover those in some detail.

and then look at some applications of those, which is language models is one of the applications. Can I make a request before we jump into it? Can you maybe just for the audience, I obviously know all this and it might be a bit weird for you. Just give a small introduction about how is it that you've come to understand this technology so well. about myself. Yeah, like a little bit of a background on you. And I'll tell you the reason why I have invited you. The reason why I do this podcast with Monica, let me start with that first, is because Monica is...

my favorite person to have a conversation with in this world. So I was like, hey, why don't we record it? Like we have so much fun. And I think that that's what I like about you. Like I also really like conversing with you. Like we've been conversing for the last more than 10 years, I feel. And it's always been great conversations. Almost 20 probably. Yeah. Actually decades. Yeah. And you, so it's one, I really enjoy having conversations with you and two, I think you're like one of the smartest persons I know. Like I really think you're really, really smart. And -

(06:53.006)
Like specifically what I really like is one thing I've noticed is you really, when you understand something well, you have a really good way of explaining things. And I think you explain things simply. And I think that's a really good test to see if someone understands something well. Cause in the past also, like whenever there's been some complicated stuff, I've seeked your advice and you've done a really good job in explaining that to me simply. So like, that's why I invited you.

as a special guest on this podcast. So why don't you start with a little bit about your background and... Okay. Yeah. Well, first of all, I'm honored. This is a lot of hype, so I hope I can live up to some of this expectation at least. So yeah, we know each other since I was just thinking we met back in 2001. That's when I moved back to India. I was in the US and I joined high school in Hyderabad. So now it's been 22 years. You're my oldest friend. Yeah, a lot more than 10 years.

Yeah, anyway, since then, so we went to high school together and then after that I went off to the US and I studied philosophy and I specialized in an area of philosophy called logic. But then I went on to get a master's degree in logic and we'll talk a little bit about logic and how that's actually on the foundations of AI. So that's how I originally got interested in this field. And then after that, I originally I wanted to go deeper into that and get into academia, but I left that and joined the business world instead. And then,

I went to business school more recently and started taking some courses in computer science and machine learning. I was at Yale for business school about five years or so ago. And that kind of reignited my interest in the modern methods of AI, which is machine learning. And this was the time when GPT -2 had just come out. So I was taking a course in machine learning at Yale in specifically language models. And

That was just when GPT -2 had come out and it was - Sorry to interrupt you. At some point I would want to get into like, what the hell is GPT -2? Yeah, absolutely. Sorry, but go ahead, go ahead. So it was just a watershed moment in AI. It was like one of the most powerful like models that we've ever seen. And that kind of ignited my interest to go and work in this field. And I decided that, hey, I want to pivot my career and work in tech and work specifically in the field of artificial intelligence and machine learning. And then -

(09:09.038)
So since graduating from business school, I've been working in the tech industry. Functionally, I'm a product manager, but in terms of the types of products I work with, they've always been a machine learning and AI based products. I spent about three years at Adobe working on enterprise and consumer machine learning applications. One of the coolest things I worked on at Adobe was the Adobe Acrobat mobile application. So reading PDFs on your mobile device is like a real pain in the ass. You have to pinch and zoom all the time.

And we built this capability called Liquid Mode, which uses machine learning to understand the structure of the document that you're reading. And it converts it to a... Simplified mobile view? Yes, mobile responsive HTML style documents. So you can read it easily. I didn't know that. It's actually really cool. I mean, I'm plugging Adobe right now, I guess. But if you have to read PDFs, it's one of the best ways to do it on your mobile. And then about a year ago, I moved to Meta, also known as Facebook, which is where I currently work.

I work in the ads AI team. We are the team that builds the models that personalize ad experiences. So the models that help understand which ads are most relevant to which users. Yeah. So that's my history with AI and machine. also like along the way, I got a part -time master's in computer science when I was working at Adobe and I dug deeper into machine learning and AI.

in that time. And then right now, ever since Chad GPT came out, I've been really fascinated again with language models. I participated in a hackathon project at Meta where we built an application that generates short form video scripts for you. So, you know, Meta right now is trying to get creators on Instagram reels because we have heavy competition from TikTok. So one of the ways we're trying to do that is we're trying to get

make it easier for creators to create short form videos on Instagram. And so what is that hackathon? A hackathon is a common thing that happens at tech companies, also at universities where basically you in a very short condensed period of time, like anywhere between two days and one week, you make a small team and just build something. Just don't think too much about what it is you're building. Don't do a lot of detailed.

(11:24.078)
product spec and get leadership approval and all. It's just a way for you to get your creative energy out there and build. And anyone could be in a team. You don't have to have people from a team. Anyone can be in a team. And companies encourage that. So you can take two days off of your current day -to -day job responsibilities and go part. It's a way for companies to generate innovation and new ideas. And so I was able to do something new. I'm a product manager in my day job, but I was doing prompt engineering for this hackathon and I was writing code.

So yeah, and also at universities, it's a way for students to get exposure to building applications and actually doing things rather than just like theoretical learning. It looks like I picked the right person for the job to explain to me. Another reason why I'm so motivated to do this is like I've had a decently successful sales career. And one of the things that has been like a core tenet is I also sell technology. Like I work for Google, I sell Google ads.

And I feel like anything that you have to sell, you have to profoundly understand what that thing is. And ads, you work in the ad space now and you would appreciate how complex this world is. And I feel like I have a decent understanding, but I just feel like with this, the more I try to understand it, like more new things keep coming up and I just can't seem to keep up. So based on what you've explained, I feel like I picked the right guy for the job and yeah, let's dive into this. So yeah, I made some notes here. I might refer to them every now and then.

So do you wanna get started? Yeah, let's do it.






# S1E1: What is AI? From calculators to Machine Learning
## Notes
# S1E1
## Transcript
(00:00.11)
So do you want to get started? Yeah, let's do it. So I think the first thing I want to talk about is what is artificial intelligence? And like one definition I looked up is that basically it refers to computer systems that are capable of performing tasks that typically require human intelligence. So like anytime a computer program can do something that you think requires human intelligence, that's what we call AI. And it's a pretty vague definition because...

would you call a calculator AI? Like initially, probably, yes, you would call a calculator AI before we had calculators. People would have considered that to be AI, but the moment like that becomes easy to do, that's no longer considered AI. So it's kind of always like a moving target. Every time something becomes...

easy for computers to do, people start thinking that's no longer AI, that's just normal like computer program. Like even if you think about like computer games, basic computer games that we have, when you interact with computer opponents, like maybe there's a car racing game and there's a computer that's racing a car, that is AI. Like the computer is driving the car on the game. But today, like we don't really think of that as AI. So you're trying to say that AI has been here for a while, is this like a...

in our general consciousness, the word AI has been increasingly popular recently, but in some sense, AI has been around, all of these things are AI. Yes. And if you go far enough back, you can think of any kind of technology as in some sense, AI. Before we had calculators, we probably had an abacus and the old thing that you move beads on. That's a rudimentary form of AI. So is this a matter of advancement? And I think...

It's always a moving target. AI is always referring to the next big thing that computers can't do right now. So anyway, we're right now going through like a revolution where AI programs are doing more and more than ever before. But I think it's helpful to break down the different like approaches to. So when, before we think about machine learning and what machine learning is, let's just think about two broad approaches to how AI can be approached.

(02:14.958)
Yeah, I mean, what is machine learning in relation to AI? First of all, that's... So machine learning is a particular approach to AI. That's basically it. Like AI refers to doing any tasks that require human intelligence. And machine learning is one of the ways to make... Yes, is one particular approach. And in fact, there's a nice graphic that I found that explains this, which is AI is this big thing. There are two broad approaches to AI. There's what's called rule -based systems, and then there's what's called machine learning.

And we can go into the differences between the two. And within machine learning, a subset of that is neural networks and deep learning is another subset of that. Yeah, I've heard all of these terms, but I mean, it was like, okay, these are some things about AI, but okay. So these are all approaches to... These are approaches. And you can see the relation here of which is a subset of which one and which is mutually exclusive. And everything that today is really popular, chat, GP, mid -journey, what you were talking about, most modern applications are within this little...

deep learning circle over here. So that's the approach that's become most popular. So are you saying like, if like, this is the stuff where I've been super fascinated and to understand this and to fully appreciate that it's like the approach I should take is to understand how we came to this. Yeah, I mean, I don't know if like, that's the approach you should take if you want to understand the general foundations. Yes. Yeah, I like that. Okay. Yeah. I mean, there are also other approaches to this. Like, for example, one of my favorite

AI educators. His name is Jeremy Howard. He has a course you can take online. It's called Fast AI. And he has the opposite approach. He has a course that starts with deep learning. He says, forget about understanding all this stuff. It's called Practical Deep Learning for Coders. And he just gives you some high level Python libraries that you can use to start building deep learning applications right off the bat. So that's one approach. I think if you want to go and build something, that's a better approach. If you want to understand things, like,

it's useful to have some theory. So one thing, before getting into machine learning, it's useful to think about this distinction. In the early days of AI, like until about the 1980s or so, the rule -based system was the most popular approach to AI. And to understand the difference between these two approaches, we can consider a simple example of an AI task. Think about spam filtering. So one common AI task is spam filtering. So you get a bunch of emails.

(04:40.269)
And the goal of this task is to classify emails into spam or not spam. Okay, and you can take two approaches to this. One is the rule -based approach and one is the machine learning approach. In the rule -based approach, what you're trying to do is handcraft specific rules that the program will follow to determine whether an email is spam or not. And you might have rules that, hey, if it has the - If it doesn't have a subject. Yes. But I understand what you're trying to do. Yeah, it could be like -

something, then it's a spam. It's basically a series of like if then clauses. It's a logical structure. You can say if it has the word lottery winner in it, if it has the word - Nigerian prince. Yeah, exactly. Classify that as spam. Otherwise it's not spam. So that basically the original approach to AI was building increasingly complex rule -based systems to do these kinds of tasks. So going back to the computer gaming example that we talked about, like if you want to drive on a racetrack,

you can program explicit instructions and say like, if you are, you know, check all these conditions, if you're this much distance away from the wall, if you're this much distance away from the racer, then accelerate, otherwise break. But giving very explicit rules, that is the rule -based system. Whereas the machine learning approach is something completely different. That's where you say that I'm not gonna define the rules, I'm gonna let the program discover the rules based on a bunch of data that I'm feeding it. And...

We'll talk about how that works, but at a high level, that's the distinction between these two approaches. And the rule -based system is what I spent a lot of time studying when I studied logic. The original approach was that we could get smarter and smarter AI systems by making smarter and smarter rules and understanding the world better. But it turned out that approach kind of hit a dead end and it didn't have that much power. And the machine learning approach is really what gave AI systems a lot more power.

Right. Yeah. I remember I was watching like back when, I mean, it's not that AI has been popular in all of our general consciousness only very recently. It's been like five, six years. Yeah. And I took my first attempt like maybe five, six years ago. And there was a very nice explainer video by like one of the Google associated channels. And they were trying to explain exactly this is like, how does machine learning really work? And the example they took was imagine if you had to create a program that identifies oranges. Okay. There are two approaches you can take. One approach is

(07:05.261)
a rule -based approach where you say if the color of the thing that you're seeing is orange, and if it's round, and if the texture is like the little grainy, then it's an orange. But hey, imagine what happens if someone submits a photo of a black and white orange. Like we as humans would be able to identify and say it's an orange, but your program has just failed because it doesn't meet your first rule that it should be orange in color. And that's a problem with rule -based approaches. Like you'll always find some...

area where one of your rules fails, but we as humans don't have those rigid rules. Yeah, absolutely. The world is just too complex. Even in the spam example, the original approaches were like they would filter out keywords. Correct.

And then you say that, okay, like million dollar lottery is filtered out. But what if I'm just genuinely writing a mail to you? Imagine missing out on a million dollars. Or it could just be that I'm making a joke. I'm like, hey, I read this article about a million dollar lottery. It could be any number of things. But yeah, it's too complex to like model. And these systems have always failed. Right. As the complexity increases, rule -based models hit a plateau. Okay. Yeah. That makes sense.

So one good way to think about what is the difference between machine learning and rule -based systems is this diagram actually, which I really like it. I saw it in one of my machine learning classes at university and it really helped me understand what is machine learning. So in classical programming, which is the rule -based approach, what you do is you create a program, you feed in the rules and the data and you get the answers out of it. The answer in this case being like spam or not spam. Right. Okay. But.

In machine learning, what happens is you feed the data and the answers into the machine learning program and as the output you get the rules. So that's like the key difference between these two approaches. In one case, you're explicitly providing the rules. In the other case, you're providing the answers and you're getting the rules as an output of that. So that I would say is the key difference where you're saying, I'm not going to try to...

(09:11.821)
learn what are the rules here, what distinguishes spam from not spam, I'm just going to provide a bunch of data and let the system figure out what are the underlying patterns in that data. Right. And I mean, the ultimate goal in both scenarios is actually to get to answers, because the ultimate goal is to provide an input to the system and be able to determine if like a...

put it under a model and see if you get an answer or not. Yes. I guess you could make a distinction here between within answers, you can say like known answers and unknown answers. So in the machine learning terminology, we call it training data and validation data. So like, you know, training data is like what I train the model on. And then I have to go and test or validated on data that it hasn't seen before. So, you know, I might have a set of like maybe 10 ,000 examples of spam and not spam emails.

And that's what I'm calling answers here. But my ultimate goal is to go and use this on emails that have not yet been written, emails that are gonna be written tomorrow or next year and apply the same rules to those emails. And yeah. That makes sense. That's the ultimate goal. So yeah, I think then we can talk about some of the basic concepts of like, what is a model to start with? Like, because the output of machine, like ultimately with...

a machine learning system, what you're going to get is like a model that will predict new answers for you. And the definition of a model is basically, it's a representation of a system or process that can be used to make predictions. That's ultimately what you're trying to make predictions about the future. So if I understand the way you're going through this correctly, so what you said is somewhere in the 1980s, folks realized that the classical programming approach,

hits a wall and if you need to make advances in computer science or just advances in our original pursuit, which is to make our systems more human intelligence, then we need to take a different approach. And that approach turned out to be machine learning is what you're saying. So now advances started happening in the machine learning field. So the genesis of this field was somewhere in the 1980s. And so we'll get into that now. Like what are some - And most recent advances,

(11:25.165)
Neural networks and deep learning have seen the most advances in the 2000s in this century, and particularly in the 2010s, I think, because the scale of computational power and data that's needed to make them very useful has only recently emerged. But yeah, before getting into neural networks, let's talk about, I'll start with what I would call classical ML. That's like machine learning that works.

pre -2000, let's say, it didn't need a ton of data and a ton of computational power. Right. And you're saying to understand that even the classical ML approach, you have to first understand what training data is. And then I think you were getting into what training data is. Yeah. Or like, what is a model to start with? Yeah, actually, let's start with that. I came up with a list of like, what are five components of like what a model is. Okay. So these are five things. This is a simplified view. There are probably more things, but you need to know what is the model architecture. And you need to know what are the features of the model.

And then the model will have parameters. It'll have an objective function and it'll have a training algorithm. And if you have all these five things, you have a model that you can use to go make predictions about the world and go predict whether an email is spam or not spam or whatever task that you want to do with it. You're saying ultimately a model is a prediction making engine. Yes. Okay. Yes. It's a prediction. Okay. Okay. I understand. And then these are the components typically. Yeah.

that go into building a model. And so I think I wanted to start with a simple example of a model. One of the most simple machine learning models is called linear regression. We can start with that and we'll take a very scary sounding name. Yeah, but it's actually make it like accessible for me. Yeah, so this diagram I think does a pretty good job of making it accessible to you. It's just basically a line. It's a line on an XY plane. That's what regression is. So basically here,

What you're trying to do is the task here is to predict the price of a home. Okay. Okay. That's the task. You're like giving a home, predict the price. And what do you mean given a home? Like I see a home. Yeah. Usually you would have a data set with a bunch of houses listed on it, but you could think about it as like Zillow, right? How does Zillow work today? When you go on Zillow.

(13:38.477)
or Redfin. if given certain features about it, can I predict the price of it? Zillow will give you this thing called a Zestimate, right? It tells you what it, yeah. And the Zillow's estimate is way more complex than what we're going to talk about here. It's also absurdly wrong or whatever. We can get into that. I have a conspiracy theory is that the Zillow estimate actually ruined the real estate market for everyone. Zillow estimate and the Redfin estimate. Okay. Yeah. Anyways.

Okay, we can talk about that. Or maybe we can talk about it after this example. I'm curious why you think that. Yeah. So in this very simplified example, there's only one feature we're using, okay, to predict. And this feature is called number of rooms. So just assume it's very simplified. We say there's one feature I use and I'm going to predict how much the house costs. It's probably going to be inaccurate or maybe in a world in which you restricted it to like, I'm only looking at

homes within a certain area where all other things are fixed, you might say that. No, I agree with you. I think, yeah, like if you had to take like one thing as a predictor of the home price, like one basic thing to start with, it could be number of homes. Yeah, you pick square footage or number of rooms. It's not gonna be right, but it's a good indicator. Yeah. So the only reason I picked this example is to like explain like what these things mean here. Got it. So model architecture, that just means like, what is this model?

It's like the underlying structure of the model. And in this case, the model is just this equation that says price equals 100 plus 50 times the number of rooms. Okay. Cause that's the line that fits best with the existing data we have. Right. Okay. So you're saying you have some existing data with a bunch of houses with the number of rooms in those houses. These are the data points and the prices of the house. You plotted them on this line. No, you plotted them first and then you tried to find what is the line that best

fits those data points. So we covered the first thing, that's the model architecture. Features, as I said here, the feature, there's only one feature. Feature is basically the input variables or the attributes that you consider of individual data points. And here in this simplified example, there's just one feature. Number of rooms is the feature. Is the feature. Go back to your previous slide. So model architecture is in this case, linear regression. Linear regression, yeah. Because it's like one line. Yeah.

(15:50.541)
Right. And features is the number of parameters? No, no, parameters is different. sorry. Yeah. Features is the input characteristics. OK. Yeah. OK. So next is parameters, actually. So this model has two parameters. You can see them here. The number 100 and the number 50 are the two parameters of this model. OK. So 100 is called the intercept and 50 is called the coefficient of the first feature. OK. So in generalized way, you will say that.

the out like y equals b plus like beta one x one plus beta two x two that that's the linear regression formula where for every fee as you add more features you'll get more parameters. Right. Each feature will have its own coefficient. So the parameters scales with the features. Yes. Is it a one to one ratio like in the case of linear regression. Yes it is one to one. But no often it's exponential. And then when we talk about GPT

Remember GPT -3 has 175 billion parameters. This model has two parameters. So I want to build up some of the intuition here. Yeah, actually I heard this before. GPT -4 has a trillion parameters. GPT -3 has a hundred and seventy. So I want to know how do I think like, okay, a billion and trillion is a cool number. Like I understand like, something big is happening. Yeah. But how do I think about this? Are you saying that every time I'm talking to GPT -4 versus GPT -3,

When I ask GPD for a question and when it answers me, it looks at a trillion things every time. 175 billion. Yeah. GPD3 looks at... So just start with this example first. Every time you interact with this model, you give it a home. By giving it a home, that means you just input the number of rooms and you ask it for the answer. It's calculating two parameters and giving you the answer. Right. It's saying... But in this case, my input is...

scaling with the number of features, right? Like in the case of GPT, the input is a simple prompt. yes, but actually internally there could be a lot of things. So for example, the features don't have to correspond to the inputs. I could create a feature called the square root of the number of rooms. Got it. Yeah. And suppose I have two features, like number of rooms and square footage.

(18:07.085)
using those, I could create like many more features. I can say the product of the square footage and number of rooms is another feature. The square of the number of rooms times the cube of the square footage. So I could create like, you know, a hundred features with just those two inputs and that would have a hundred parameters. So that's often there's a balance. Like as you increase the number of parameters, you can get more predictive power, but you have to find the optimal number of parameters. Sometimes if you have too many parameters, you might

overfit the data, you might just be having too much like computational expenditure that's unnecessary. Let's not get ahead of ourselves. I think I have a good understanding of - But there's a good thing to keep in mind that this model has two parameters. GPT -3 has 175 billion parameters. And along the way, when we get to neural networks, I'll show you another model that has like about maybe a hundred thousand parameters. And that'll be a good in between. Right. Okay. That makes sense.

I think it also helps me put in context when I hear stuff like, GBT4 has a trillion parameters. Yeah. So think of parameter as like the number of knobs that can be turned. Like what are the different things that the model can tweak in the training process? Because all that's happening in like model training is it's actually that's the next topic we're going to cover is model training. So we talked about parameters. Now next we have to talk about the objective function. The objective function is...

So we start with just these data points. There's no line here. We don't know what the line is. The line is just what we came up with as a result of training with a given objective function. So in this case, objective function is just what you're telling the AI system to optimize for. I see what you mean. So one objective function we're using in this case is the price of the home. Another objective function. No, it's not the price. Sorry. Price is the output that you want. The objective function is...

Suppose I give you like a line that looks like this, okay? And a line that looks like this. How do you evaluate which of those two lines is better at predicting the price? Well, I mean, the line comes afterwards, right? Like first you plot houses with their number of rooms and the prices. That's given to you. You have like, you have a data set of 10 or let's say you have a data set of thousand homes and you know how many rooms each home has and what the price of each home is.

(20:26.061)
You plotted them on this. I'm going to draw a bunch of lines and see where most of the homes fit, like which line most of the homes will fit in. And that will be the line that I'll use. Yeah, okay. So actually just expand that further. What exactly does that mean? Yeah, you draw a bunch of lines. How do you evaluate if one line is better than the other line? The line in which most of the data points will fit in, like, or coincide. What do you mean by fit in? Like there'll be exactly on the line? Or close to the line. Okay. What if I have a, you have a line that fit, say there are like,

thousand data points, you have a line that fits like maybe like, or sorry, it's hard to think. Let's think about just 10 data points. I feel like somehow calculus will get involved here. Like you have to find the closeness of the data points to your line and figure that out for every line. And then finally it'll like be some value, which we'll show you. Actually, that's exactly it. So it's not how many fit on the line because there could be some that are just

far away, you're trying to minimize the distance. Maybe calculus will get involved somewhere over here. Cause yeah, now I'm going back to my high school days. Yeah, absolutely. So in this case, we use an objective function called mean squared error. Basically you're look error is basically the distance between an actual home price and the predicted price. What's on the line. That is called the error. So here error could be like $50 here. Actually this error would be minus 50. This error could be plus 50.

That's maybe plus 10. So actually the reason we square it is because if you sum up all the errors, the plus and minuses will cancel themselves out, but that's still a bad line. And so what they do is they take a mean squared error. So for each line, you compute the objective function as the mean squared error. So you look at all the errors for each individual data point, you take the square of those and then you average them out. That's the objective function. And then that's what you can use to, if you draw like a thousand lines,

to figure out which is the best line. So, and then the last step is the training algorithm, which is actually generating this line or this model for you. And actually the way you phrased it initially is a pretty good way to think about it, which is randomly generate like a thousand lines and evaluate them on the objective function to choose the best one. But there's a more sophisticated way of doing that because this process would take like too long if you just generated like.

(22:51.085)
thousands of lines. One of the coolest innovations in machine learning is this training algorithm called gradient descent. What it does is first it plots a random line, it just assigns random values to the parameters, and then it looks at the, this is where the calculus comes in, it looks at the slope of that with respect to the objective function and tries to figure out which direction to go in.

So it's like, you know, do I go, instead of generating - I see, I see. Let me finish your thought and see if I'm headed in the right direction. Monica and I do this. If you find it annoying, then we'll like, cause I interrupt her all and she's okay with it. So what you're saying is instead of drawing a thousand lines and figuring out the line which most closely aligns with your objective function. Yeah.

you draw one line and you move that one line in the direction of what will ultimately be your objective function. You first draw one line and then you figure out which direction you need to move in. And you keep moving it in that you shift the... Here you have only two parameters to play with. So the model is going to play with this. Suppose we call it B and A. It's going to play with B and A, but it knows which direction to move it in to get to a better objective function value.

So yeah, it just keeps doing that until. Right. I'm trying to see why this is needed because like right now I have an example of like a very simple model. Yeah. And I'm like, why do you need to go through all that? You just see where the line will be obvious to you, but the line will not be obvious to you when you have an insanely big model. So actually even the moment when you have like three or four parameters, it's already too complex. You.

You can only visualize one parameter. Yeah, like I don't even know how to visualize. If there are two parameters, I mean, sorry, if there are two features, that's a plane. It's not a line anymore. It's a 3D space. And after that, I don't... Yeah, I've seen a lot of videos and like people trying to explain how to think about fourth, fifth dimensions. Whenever I see those videos, I'm like, yeah, that's cool. But like the next day I forget. Like, I don't know. Like my mind can't process more than four dimensions. So I see what you mean. So and then with machine learning, you get into multi -million dimensions. Right. Yeah. Right. So this is just a simplified example to understand the concept, but...

(24:58.477)
I think the coolest thing is that we have this algorithm that can tell you how to set your parameters such that you'll get to the best objective function value. It'll start with something completely random and it'll automatically adjust itself until it gets to the optimal value. So that's the cool thing about machine learning. So yeah, I mean, we could go into the details of gradient descent, but yeah, it's pretty technical.

So that's pretty much like what classical machine learning is. And there are many different types of algorithms. Regression is one. There are different tasks you can do. Regression is trying to predict the price. Classification is another popular task. Classification is like, I have two classes and I'm trying to predict orange and not orange, or spam and not spam. But it's the same general idea. So that one's classification and this one's? Regression. Regression, where? Yeah.

It's not a yes and no, but it's a value that you're trying to put. Classification has discrete outcomes. Regression has continuous outcomes. So it's like, yeah, there's continuous any real number, right? Between one and something. But the ultimate objective of a model is to predict something. Yes, either classes or value. Depending on the nature of the thing that is being predicted, you have different types of models. And the two popular ones are regression models and classification models. Those are not models. There's like,

There are the two common types of, yeah. And then there's generation, but that's a new thing. We'll talk about that later. But yes, so you can even think about, we talked about ads, right? So maybe before we get into neural networks, let's think about how this can become even more sophisticated. So what are you trying to do in ads personalization? I am trying to predict for you, for a given ad, are you going to buy this product or not? Right.

maybe that's too complex buy or not buy. Let's say, are you going to click on this app or not? There's something called predictive CTR. Exactly. Yeah. Predicted click through rate. So what I'm doing is it's exactly similar to this. No, I don't have a slide on that, but I have a training data set that has a bunch of clicks and I have a bunch of characteristics of users. So I'm like, there's a large data set and I know the label. In this case, the label is like the price.

(27:22.445)
In that case, the label would be click or not click. It's a classification problem. And then I have a bunch of input features, like maybe there's profile information, like a person's demographic information, behavioral. Yeah. Mostly it's behavioral information, like about what activity they did in the past. And so I can already think of like, there'll be so many parameters that one could gather. Yes, exactly. Those are already huge. They have several parameters. And what you're trying to do is figure out.

optimize those parameters to get to a prediction of whether you're going to click on it or not to optimize for that objective function. So most actually tasks that are used in businesses today are just based on like what I would say is classical ML has nothing to do with like generative AI or any of the new stuff. So like ad predictions, like recommender systems, which is very similar to the ads use case. Yeah. I mean, I spent the last seven years of my professional career selling.

Exactly that, like an algorithm which can help you predict if you should be participating in this auction or not, because most of Google media is sold on auction and like how valuable is the user and what not. So yeah, okay. So that's classical ML, like the stuff that I've been selling or like the technology that I primarily do. Well, it possibly uses neural networks, which we'll get into next. It probably does, or it's not clear. Sometimes they do, sometimes they don't.

Maybe with classical ML, it's already good enough. It depends. Right. Okay. So next, let's go beyond class. Yeah. Okay. So let's go to neural networks then that that's the next thing here.



# S1E2
(00:00.046)
Okay, so next, let's go beyond classical. Yeah, okay. So let's go to neural networks then. That's the next thing here. So the concept of a neural network, it comes from, it's inspired by the human brain, where the brain consists of a bunch of neurons that are either activated or not. And each neuron, so we have a bunch of neurons that are interconnected. Yeah. And neurons activate in regular patterns. Like when you see an image of, or when you have like a happy moment, say when you see your daughter.

right? And you're happy, you have some emotion that activates a certain set of neurons and there's a pattern to that. And that activation then has a certain output, which is like you feeling happy. So basically the idea is, can we construct an artificial system that's somewhat similar to that with a bunch of interconnected neurons and try to figure out patterns of activation that map to certain types of input?

It's very abstract, but I can actually go into an example. Help me understand it this way. Like, I really like the way you, like we, the reason we went into machine learning is because you explained to me the challenge with the classical approach to programming. It's like, when you do rule -based programming, after a while, you hit a wall, which is why you needed to find new and novel approaches. And the new and novel approach was machine learning. Now, like, is it similar to that? Like, did we hit a wall with classical ML that - Yes, yes.

for which we needed to pick. Firstly, you need to handcraft these features. You need to know what are the exact features I need, like number of rooms or square footage or whatever. That's one. But I would say the main wall you hit is it can't work with unstructured data. Like this is...

So there's a distinction between structured and unstructured data. Structured data is like this. It's the kind of thing you would put inside a SQL database. Like a spreadsheet or something. Or a spreadsheet. You have rows and columns, and this is very structured data. Named rows and columns. Yeah, exactly. What is unstructured data? Unstructured data is like a paragraph of text. Unstructured data is an image. That's completely unstructured. So the classical ML is not good at dealing with unstructured data.

(02:09.55)
I can't feed it an image. I don't even know what am I doing with this image. So actually the one example I want to talk through for neural networks is image recognition. So there's this very famous task, it's called handwriting digit recognition. There's a database called MNIST. I don't even know what it stands for, but basically it's a bunch of images of handwritten digits from zero to nine. People handwrite, like you write seven, eight, whatever. And the goal,

the task there is to figure out from the image what number is represented. Okay. Okay. So think about that task. I have, I'm just giving you, it's like, dude, I don't even know where to start. I, yeah. How would you even, what is the feature here? How do you extract a feature? So this stuff doesn't work with that context. I've thought about this before and I was like, I don't even know who to think about this. Like, first of all, how do you even get the machine to see that handwritten thing? Like I'm, I'm like lost.

There already. Yeah. Like what is it? See, it let me explain to you what I mean. When you let's say my baby girl, Isha, she's six months old, right? Yeah. I'm going to show her an eight. Yeah. She does not know what an eight is. For her, it's just an abstract squiggly line. But at least she can see that in a white piece of paper, there is a contrast and she can determine that there's a squiggly line in the shape of an eight.

I'm saying how do you even show the machine? Yeah. Because the machine only reads zeros and ones. Yeah. First, you have to tell the machine that this within the zeros and ones, there is like a white paper in which there is a squiggly line in this pattern like that itself seems so challenging.

So that's actually a great question. I think that's a really good segue. You can't do that with this, but you can do it with neural networks. And I can explain to you exactly how we will do. That'd be amazing. Cause I always, do you understand my question? Like I have the answer to your exact question next. Okay. So this is abstractly what a neural network is. And this will become more clear with this example of the handwriting recognition that we're going to talk about, but there are some certain, there's an input layer and then these are the things that are called neurons.

(04:23.534)
Each neuron is like a neuron in your brain. We don't actually know if this is how the brain works at all. It's just a theory, a hypothesis. But what happens is each neuron either gets activated or not. And then that signal passes through to the next layer. And finally, there's an output layer that gives you the answer you want. This probably doesn't make sense now. Let's go through the example, and then we can see how it makes sense. So.

Yeah, so the input layer, it receives the inputs, the output layer is the final layer that creates like the response and the hidden layer is what's doing the manipulations in between. Like it's doing the... What example are we following here? It's that... Handwritten recognition. Handwritten digit from anywhere between 0 and 9. 0 to 9, yeah. The goal of this thing, this model, is to predict... Which digit that is. Yeah, exactly.

So in that case, actually, let's think about what is the input layer to that, okay? What am I gonna input from the image? Like, do you have any ideas? No, I mean, that's my question. Like, how do you break down an image to a machine? Am I wrong in thinking that a machine can only see zeros and ones? Sure. Like a machine literally can only see a high voltage or a low voltage, which is then represented in zero and one.

So let's take a simplifying example. Let's say these images are all black and white. Or let's say they're grayscale. That's like simple. So grayscale. And in this particular data set in MNIST, they're 28 pixels by 28 pixels. And 28 multiplied by 28 is 784. So there are 784 pixels. Each pixel is an input.

And the value of each pixel is between 0 to 1. 1 is if it's totally black, 0 is if it's totally white, and in between is how gray it is. That's how grayscale images are encoded. I see. OK. So if it's an 8, you'll take like a square pixelized image. 28 by 28. Right. Yeah. You sequence it into 784 pixels. And all the places where it's actually 8, let's say it'll be 1, and all the places where it's just white paper, it'll be 0. Yeah.

(06:32.654)
Or that's if it's black and white, that's what it is. If it's grayscale, it's more sophisticated. You have an entire scale between zero and one. How one is most black, zero is most white. For simplicity sake, let's take black and white is like a squiggly line. Yeah, that is zeros and ones. Exactly. Pen to paper is one. Yeah. Only paper is zero. Let's simplify it. Okay. Yeah. Okay.

Yeah, that's a simplified example. Realistically, it would be grayscale because there are some places where it's like maybe, yeah. And it's easy to generalize this to a color image, like because color, it just, you break it down into RGB values and you say 784 pixels times three for each pixel, I'll give you an R, G and B value. That's how you convert it. that's another computer.

Cool computer thing that you can break down. I mean, well, I've computers adopted it from the primary colors, but yeah, I see what you mean. Yeah, you can compose. You can create any color from RGB, basically. Exactly. So in this case, let's just simplify it and say it's only grayscale, or you can think about it's only black and white. 784 pixels, that's the input layer. What you want out of the output layer is finally a number, right? One to nine. But realistically, what happens is your output layer has nine neurons. Each of them are numbered zero to nine.

And the output is a prediction of between probability of how likely is it that this image is a eight. So suppose you feed it a seven. And if it's my handwriting, it's you. Yeah, because ideally, sometimes there will be an it won't always be 100 % certain. So like a four may look like a nine, depending on how you do it. Yeah. Got it. OK. So the goal is that when you feed in a seven,

All the pixels go in and the layer corresponding to seven is the one that lights up the most. So let me show you an example of what this looks like, this neural network. So the input layer is, as I said, 784 input neurons. That's how big the input layer is because we said 28 by 28 and that's each pixel. And yeah, you can think of these greens as the activations. The blank ones are not activated. In this case, actually there's shades of green because it's grayscale.

(08:39.758)
And then this output layer for this seven, it's activating the seven, which means that it correctly recognized that it is seven. And then there are these two things in between called hidden layers. That's where the manipulation is happening. That's where the weights and parameters are coming in. That's the magic. That's exactly where the magic is happening. So it's just like the case earlier we talked about with linear regression.

First, you start with some random way of activating things, and then you evaluate the loss, and then you look at how do I optimize this. So actually, let's go back to this list here and think about what all these things here correspond to. Maybe you can start with features. That's an easy one to start with. In this case, there are 784 features, each pixel value. That's it.

Right. Where in the home prices case, remember we had square footage or yeah, we had only one feature. In this case, we have seven hundred and eighty four features that we're putting in model architecture. It's a little complex, but it's what I showed you in that diagram instead of linear regression. It's neural network. It's a neural network. Yeah. Parameters. OK, before we talk about parameters, let's talk about the objective function. The objective function, again, as always, is to minimize the loss. So just as remember in the.

regression case we talked about. You start with one random line and then you move it towards... Yeah, but what is the objective function? We're measuring what is the distance between that line and the actual data block. So in this case, what we do is once we create a model, we put all our data through it and we measure the distance between the predictions and the actual values. That's always what an objective function is. You want to minimize...

the distance between your predicted values and the actual values. So the predicted values, for the data set you fed it, it may be like zero, one, two, whatever, actual values, maybe something completely different. And you come up with a way to measure the distance between those two. That's the objective function that you're trying to minimize. And then - so I see what you mean. So you're saying that in this case, in this model, you'll start with, let's say, 100 examples.

(10:46.862)
Yeah, that's the training data. Yeah, the training data would be a bunch of papers, 28 by 28 pixels, where you've written a bunch of numbers. And obviously, you know what the number is, so you're training the data. So you'll start with your 784 input data. You obviously know what the answer is, so probability will be one. But what's happening in like, what actually happens during the training? Let's talk about that. So let's talk about what's happening in these hidden layers. So...

There's a thing called an activation function here, which is there are lines connecting every node to every other node in the next layer. In this architecture, we're just assuming I have two hidden layers. Each of them has 16 neurons in this example. It's just arbitrary. We can't really get into like why there are 16. Arbitrarily, we assume there are two layers and 16. This is describing what's happening at the first layer for each connection between

a neuron in this layer and a neuron in this layer, it has a weight. Okay? So these all have activations that are A1 through AN, and then they all have weight. So suppose here, I want to compute the activation here. Why is this green? Why is that lighting up as opposed to not lighting up? So what I'm doing is I compute the activation function of that neuron. This neuron is connected to 784 input neurons. And through this function here, it's just a random set of weights and biases.

I determine whether this should be activated or not. And it's gonna give me like a one or a zero, or it could be anything between a zero and a one. So that's, it's gonna output an activation. And then the same thing is happening at the next layer again, but much smaller, cause I have only 16 now. And the same thing is happening at the final layer.

So there are only 16 things here. So does it progressively reduce the hidden layer? So like the first 16, the next one's what? In this case, they're both 16, but it progressively does reduce. Yeah, it reduces them. And then eventually it comes to the number of... So the idea of what we think is going on here, we really don't know, is that each layer is developing some abstraction over the... Like the first layer is literally looking at individual pixels. The next layer we think is learning some...

(12:59.886)
patterns behind those pixels, like, does it have a straight line? Does it have a loop? Something like this. And then each subsequent layer is a higher level of abstraction until you get to the final layer that tells you what number it actually is. That's what's happening in this. So now I just want us to think about how many parameters there are here. So each neuron is connected to each other neuron in the next layer. 784 connected to 16 neurons here.

And each one also has a bias. Bias just means like in this case, like this parameter that's not a coefficient of any feature, we just call that the bias. Right, right. A hundred in this case is the bias. A hundred in this case. So in this case, like each neuron has its own bias and N weights. So are you saying that, so the hidden layers, right now for simplicity sake, there are only two hidden layers, but it could be any number of hidden layers. You're saying the first one,

When you start training the data, you just start with something random. Yes. Not the, you've, okay. First, let's think about what all the parameters are. Let's go here and see there are going to be 784 times 16. This is the number of parameters for these connections. 16 times 16 is the number of parameters for these connections. And 16 times 10 is the number of parameters there. And there are this many biases because each neuron has its own bias. So there are 13 ,000.

parameters in, sorry, I'm getting sun in my eye. There are 13 ,000 parameters in this model. So remember we talked about with linear regression, all that's happening is first you initialize a random set of parameters and then you move towards the right direction to get the right parameters that are minimizing your loss function. Loss function is just the inverse of objective function here that are optimizing your objective function.

And the way this happens, it's a combination of something called back propagation and gradient descent, which we talked about earlier. So when there's an error here, like, you know, suppose it recognized the ones as zeros instead based on the error that we find from the objective functions value, it knows like how to propagate backwards and adjust the weights to get to the right direction to optimize the objective function. So.

(15:24.238)
That's all that's happening is it's just like linear regression on like a hyperdimensional scale. You're just tweaking the parameters in an intelligent non -random way. You could theoretically, like remember originally you said like we can draw a thousand lines for regression and find which is the best. Theoretically you could do this. If you had infinite computational power, you could just generate infinite combinations of these 13 ,000 parameters and just say select the best one.

That itself would be like a way to do it. But since we don't have infinite computational power, we want to optimize. We want to test only the relevant combination. So every time we know which direction to go in based on this gradient descent thing, and it moves in that direction and only tweaks the parameters in one way until it gets to the optimal set of parameters that can most accurately predict.

So what I understand from this is that the breakthrough over here with neural nets. So I'm gonna summarize our story. Our story is classical programming hits a wall. Then you have classical ML hits a wall. Then the breakthrough is neural nets. What's the breakthrough with classical ML? The breakthrough is instead of you programming the rules, the algorithm figures out the rules. What is the breakthrough here? Is it the hidden layers?

And this back propagation thing, the breakthrough is that you don't need to figure out how to structure the data. Like remember in the classical ML, I have to structure the data and say, this is the feature. Like the feature is like the number of rooms or the number of houses. Right here. You don't have to structure the data. I just give it 784 pixels. I see what you mean. Yeah. You're just giving it raw pixels. Yeah, exactly. Or in the case of language models, which we'll talk about next is raw text.

Right. You'll give it. Right. Okay. Got it. So I don't have to structure the data at all. Okay. Okay. And I don't have to structure the features, because again, in classical ML, typically there's a lot of hand crafting of features that you have to do. In a regression model, sometimes you will find that linear regression may just be the wrong example. Linear regression means there's a straight line relationship between the two variables you're trying to plot, but maybe there isn't. Maybe it's a polynomial.

(17:38.862)
like equation. So it takes a lot of time to customize and find the right one that fits your data. In this case, you have to do none of that. Right. It's just an abstract structure that can apply to like many different types of data sets. It also sounds to me like every next evolution, we're making it simpler in some sense. Obviously, we're taking advantage of the massive computational power, but can we? Yeah. So like, let me explain how I mean it. So in the first case, we had to do the one -on -one

Like we had to create the rules, right? Now in classical ML, you don't have to create the rule. Can we get the hazy? In the classical ML, you don't have to get the rules. So like from the programmer's point of view, it's simplifying your job, right? Like you don't have to do the rules, but you still have to like figure out the features and what. Yeah. But there are some trade -offs that come here because one thing that goes down is interpretability. Like I don't under, like in this model now, if you tell me that look based on,

this input, I got this output and you tell me like why? Yeah. I can't give you the answer. I'll say there are some 13 ,000 parameters in there. I don't know what they're doing. They gave me this answer. That's another thing you have answered one of my questions because a lot of times I've heard people say like the black box nature of things and you don't really understand why it's doing. This is where the black box comes in because in the case of the linear regression, it was very easy. If you give me I know exactly what parameter.

corresponds to which feature because the parameter is the coefficient of a feature. And if you give me a new house and my model predicts that your new house has a low value and you ask me, hey, why does my house have a low value? I can tell you exactly why it has a low value. I'll say, hey, my model multiplies your number of rooms by 50. Your number of rooms is low. So like your house price is low. That's a really good example. That's why, like if he...

like one of the concerns that people have is like increasingly with algorithms making a lot of our decisions, which is happening, right? Like increasingly, it's gonna make a decision which might seem unfair to us and there is nothing we can do about it. And no one will be able to explain why that happened. Is that why we're like one of the examples I can think of is like, imagine you apply for something and if your application is denied, I'm abstract, I'm generalizing it like some application and you just deny. A credit card application is a good one. And imagine like,

(20:01.582)
your application is denied, but you are not given an explanation why that happens. Because no one knows the explanation. Like once you get into these, once you increase the, like two parameters, 10 parameters, yes, it's okay. I can explain to you what's happening. Once you get to 13 ,000 parameters, it's like no one understands what these parameters are doing. And there's some effort going on right now into ML explainability, but it's hard. There's a trade -off between,

models that are more powerful versus models that are more explainable. And that's just a challenge. I think, yeah, that's okay. I understand. So with every new breakthrough, you're getting more powerful models. But obviously there's a trade -off here and the trade -off is you're losing a view into what's actually happening. Because like this thing here is a complete black box. Like nobody, no human being can look at this and understand. Yeah, it's a scary picture. Yeah. Like, you know, mathematically, maybe you can understand some of the equations, but

Literally, you're just saying, like, there's a bunch of random, usually this is treated as a vector in, because you don't say these are 784 individual values, you treat it as one vector with a 784 dimensions or one, yeah. And it's all these multiplications that are happening, usually they're like matrix multiplications, because you would treat them all together. So.

And that's actually a reason why GPUs are optimized for this task. Actually, that's what I want to understand as well. NVIDIA, if you have, like, I don't know if you follow stock prices or not, but like if one of the interesting stocks that you could have followed over the last five, 10 years is the NVIDIA stock, it's insane how much it's increased. And I think one of the analogies that people give is like, they've observed that whenever a gold rush is happening, the people that tend to make a lot of money are the people who supply gold miners with their equipment.

Yeah, picks and shovels. And in this case, if you extend this analogy to AI, if there's a gold rush happening, then NVIDIA is getting enriched. I understand all that. I don't fully understand. NVIDIA used to make graphic cards. What happened suddenly? Graphic cards are actually a type of processor that's optimized for every narrow function.

(22:17.134)
Whereas it's a GPU versus CPU. CPU is a general purpose computing machine. GPU is optimized for a very specific function like of rendering graphics, which actually turns out is ultimately matrix algebra. And training of neural networks is all matrix algebra because at the end of the day, you're doing like millions of matrix multiplications. That's what's going on here every time you compute.

an activation function every time you have to do that for each and every layer, like, you know, there are 13 ,000 parameters. So it's just a bunch of matrix multiplications and a CPU can do that, but it's not optimized for that. So whereas if you take a narrow machine, like a GPU, that's just optimized for doing one type of operation, it can scale, do it more cheaply, do it more efficiently. So with the rise of neural networks that made these matrix multiplications, like,

really important and that's like most of your compute resources are spent doing matrix multiplication. It made sense that we're going to build specialized hardware, GPUs and then Google built TPUs. Yes, those are also optimized for matrix multiplication. And I think they're actually even further optimized if you use Google's TensorFlow library for doing the... Yeah, I want to get into that. Not now, whenever you think it's appropriate, but I want to understand like what is TensorFlow?

What? Yeah. yeah. We can talk about that. TensorFlow is just a Python library. TensorFlow and PyTorch are the two common libraries that make it easy to do exactly. Like imagine if you want to write a program that creates a neural network. Yeah. Like you don't want to have to like sit and... I only bother about this and this.

I don't want to be bothered with this. So TensorFlow does all the hidden layers. They do the hidden layers. They do everything. They create all that. You can define how many layers you want. It is just an abstraction layer on top of this neural network. And it does the training algorithm. You don't have to code how to do gradient descent, how to do back propagation. They have that built in. So that's ultimately, they're just like high level Python libraries that make it easy for you to interact with these.

(24:29.838)
Low level concepts. And yeah, Facebook built PyTorch, Google built TensorFlow. They're both pretty popular. I don't know how things will change now with like LLMs and stuff. We have to see what happens. But yeah, so that's... Yeah. So the big breakthrough first with the classical ML. Sorry if I repeat too much. It's just for my own understanding. With classical MLs is you don't have to write rules. With neural nets is you don't even have to give the features.

or structure the data. Exactly. So we're giving, well, and that way it's becoming more powerful. It's automated. And it's also like in some sense, like less work even. It sounds like, Hey, you don't have to write rules. Hey, you don't have to give feature. Just give me the raw pixels and I'll do all that for you. Obviously, it requires a lot more computational power as can be seen with scary looking math, scary looking graphs. And you're losing explainability. Yeah, exactly. So yes. So I understand.

So neural nets can do stuff like this prediction. And deep learning, if you hear the deep learning term, it just refers to a neural network where you have more than one hidden layer. That's all deep learning means. It means the network is deep. So deep learning is a type of neural network. Yes, exactly. So if you go back to the circle view, there's AI, there's classical and ML, and then within ML there's neural nets and deep learning is type of that where it's more than one hidden layer. Yeah, exactly. Okay. Okay.

So now we're down to deep learning, which is more hidden layers. And now we can do more complex things, like image recognition. This is just a basic example, like handwriting. And we can also do text. So that's the next thing. So we wanted to talk about generative AI, right? Yeah.



# S1E3
(00:00.398)
So we wanted to talk about generative AI, right? Yeah. So we can next move into how text is dealt with. So first question is, how do you encode text, right? The first question we had about images was, how do you encode an image? And then we said, OK, we look at each individual pixel. And each pixel is encoded in RGB value if it's color, or 0 to 1 if it's grayscale. Now, how do you encode text? So this is actually very complicated. There's.

two main steps to encoding text. Wait, that's not hard, no? Like encoding of text is something that computer scientists have like ASCII and like binary, all that is encoding of text, no? Yeah, sorry. I mean to say like encoding it in a way that can preserve some semantic relationships. I see what you mean. How do you infer meaning from it? Yes, exactly. Because so far it's only been manipulation of bits. Yeah, you can arbitrarily come up with some encoding that doesn't like, yeah, but the key is can I come up with a way of encoding text?

that preserves semantic relationships, meaning of words. And I think one of the key breakthroughs there is called embeddings. It's basically word vectors. It's a method of turning a word into a vector, like how we take an image here and turn it into a 784 length vector. Similarly, you can take a word and turn it into a vector and you can do it in a way such that it preserves the...

semantic meaning and relationship. Give me an example if you can. Yeah, so that's actually in the next slide. So for these, this is called word embeddings. Okay. So for each word is turned into a vector like this. In this case, these are the dimensions of the vector. They're like seven dimensions. But in the case of an actual model, like GPT -3, I wrote down how many. It looks very similar to like a concept that Google has and maybe others have as a.

The embedding dimension in GPT -3 is over 12 ,000. So this thing, the seven that you have here, they're like 12 ,000 dimensions. Yeah, like just by seeing your first example, it says cat and it says a cat is a living being. It's a feline, human, well, it's not those things, but like you have these groups. So like internally at Google, we have this thing called a knowledge graph. I don't know if it's internal, but like we have a concept of knowledge graph where like you know on Google search, a lot of times you will see a knowledge panel.

(02:24.046)
when you search for something. So let's say if you search for Barack Obama, there'll be a special result. There'll be pictures of Barack Obama and it'll say American president. Like it has all these things. So for example, the way to do that is by having a knowledge graph and it knows that this person is an American president. Like there is a knowledge graph. So every entity has...

a graph with many connections. Okay. Right. Sounds like a similar. Yeah, I think they could be related. I don't know much about knowledge graph, but it's possible that they are related concepts. Basically, what's happening here is where for each word, you're figuring out like what other words and what context does it appear in? That's what an embedding is. Okay. And you can set a number of dimensions for an embedding. In this case, they're

there are only seven dimensions and they're all like very interpretable, which is unrealistic. In reality, there are going to be thousands of dimensions and you can't really interpret them. But the key point is like, what you're doing is figuring out this word, what context does it appear most frequently in? And that's what an embedding is. It's saying in these contexts, it appears more frequently. So you go through your entire corpus of training data and figure out in which context the...

word appears more versus less. So yeah, in this case also, you could just give it a lot of unstructured data and then you can figure this out. Meaning you give it all the text that's ever been written on Reddit, which is a lot. Even more like trained on three billion or some number of billion tokens. Three, I think. I don't know what tokens is, but I see what you mean. Meaning you can keep it super unstructured and it'll create an embedding out of whatever data you give it. Yes.

And will that happen for every single word within that training data? Yes, absolutely. So GPT -3 has the vocabulary or size of GPT -3 is 50 ,000 words and the embedding dimension is about 12 ,000. So in fact, that leads to it having six. That means every word has 12 ,000 columns and its relation, like how frequently does it come with those 12 ,000? That's insane. So what is that? 50 ,000 multiplied by 12 ,000 is about 600 million.

(04:33.486)
That's the number of parameters. But that's only like the beginning. Remember, it has billions of parameters. So every number here is a parameter of the model. The model can then find what is the right value for this parameter. So right here, there are going to be, as we said, 600 million plus parameters with GPT -3. But before talking about parameters, let's think about what is the value of creating these word vectors. As I said, they preserve the semantic relationships between

words and concepts. So to give you an example, look at this graph here. This is a visualization of these word vectors for man, woman, king and queen. And what you can do is you can do vector algebra. Probably you learned this in high school, like vector algebra is you can add and subtract vectors from each other. And one cool example is if you take these these vectors, you do king minus man plus woman.

the result it gives you is the vector for queen. You do father minus man plus woman. You're saying that there's an independent field of study in mathematics, vector algebra. And like the researchers realized that if you were to create these embedding, yes, you could use words to vector. You can use the algebra that they have figured out over here. And this pattern keeps seems to repeat a lot in science in general, right? Like,

There'll be some independent field of study somewhere and then there'll be like some emerging tech somewhere and then they realize, we could like use all this stuff from this other field of study. Sounds like that's what happens here. I think one of the earliest times this happened was with Descartes in the 16th century when they got really stuck with geometry and they realized that geometry and algebra could be related. This happened with what's called Cartesian math. Descartes in like the 16th century realized that

There are a lot of problems you're having in geometry that can't be solved. But once you map geometry onto algebra, like you say, the geometry is just like algebra on like a graph. You can solve a lot of like geometric problems that you previously couldn't solve by converting them to algebraic for problems because there are a lot of results in algebra.

(06:49.038)
that directly you could apply to geometry. Yeah, I mean, I'm sure you'd appreciate that because you studied logic, but like that's what sort of the genesis of Boolean logic, right? Some guy was independently creating Boolean logic for, I think his pursuit was to like prove the existence of God. George Boole, no, I don't know. It could be, I don't remember who. Like some interesting story, maybe I'm butchering it, but like his pursuit was to like prove God or something and he was trying to find out, I'm gonna take all these statements from Bible and then I'm gonna apply some logic and then drive conclusion. And I think he...

discovered Boolean logic and then over here, these people who are dabbling with computer science are like, we could use this existing field of study and look what we've made. So it looks like something similar is happening here. Absolutely. And I think ultimately all of it is just mathematics. Like there are a lot of results in mathematics, like a lot of relationships that people, it's about encoding different objects into a mathematical formulation and then being able to like leverage those results and relationships. And that's exactly what's happening here.

We know how vectors are related to each other. Once we convert words to vectors, then we can leverage those. This is very cool. Like those relations. You're saying that if you were to do all this, then you'll come up with vectors of man, woman, king, queen. And if you apply that vector logic, like the way you create. It preserves these relationships. Yeah, you could. Yeah. Like, because that's how we think about it. It's like, OK, man, woman, minus that, then that's a king. That's cool. OK. Absolutely. So then this is the first part of how this

is the encoding problem. We talked about how to encode our input into features, right? That can go into the model for images. It was the pixel values for words. Now you start with first tokens. A token is like an individual word. Think about it that way, like cat, kitten. These are tokens. That's step one. Is that a common parlance in the? Yes. So in fact, if you go to GPT,

3 or Chad GPT, it'll always describe its limits in terms of the number of tokens. So the context size is one of the important limiting factors of GPT. With GPT -4, I think the context size is... 25 ,000. No, it's 4 ,000 or 8 ,000 tokens. And then there's an expanded version that's like 32 ,000 tokens, but that hasn't been released yet, which means that the total of the input and the output that it can generate at max, it can have...

(09:10.958)
Why don't they use words like words? With words. Yeah, I think. What's the difference between words and tokens? That's a good question. I don't know the exact answer. I think there is a difference. Like, for example, the word man and the word men are the same two different words, but they're the same token. I see what you mean. Yeah. OK. OK. So like man or if you have like man, man's man, apostrophe s like

plurals and all that. So those are like concatenated into the same token. Because ultimately, whether it's man or like man's, they're... But actually, why are they treated the same way in the model? Because they have different semantic meaning, right? Well, not sorry, different semantic meaning, but they have different usages. That's true. Actually, I don't know the exact... I could look it up, but I don't know the exact...

relationship between words and tokens. I know that it's not a one -to -one relationship. There are some things that are bundled together, like different words into the same token. And sometimes the same word is multiple tokens based on if a word has two meanings, like then those are separate tokens. So yeah, we were talking about... So actually, if you backtrack a little, I want to go, like stick to our story. Classical approach to programming, then classical ML, then...

neural nets, then deep learning. And now we're moving to like generative stuff. This is still deep learning. This is still deep learning. Yeah. But this is now a basis for like generative. Analyze text and how to encode text. Yeah. So vector algebra is came to the rescue. And you can put it in the same thing here. Again, you can put all those vectors here and you can run it through this and you could run like a classification model like this, where instead of like zero through nine.

Suppose you have your spam problem. You can have two classes, zero and one, spam, not spam. You can put those inputs here, all those vectors. It's a little more complicated because you're just putting the individual vectors there. You need a way to get the sequence and order and things like that. So the architecture becomes a lot more complicated, but the basic concept is the same. You have a way to encode text. You can now feed that into your machine learning models and you can use it to perform tasks like.

(11:29.102)
classification, prediction. So that's how you encode text. And that's how that fits into deep learning. Yeah. And then, so I want to go back to this thing here. So we talked about features, right? And now let's think about what are some of the other things that are going on for a language model. Actually, we didn't even come to language model. How do we get to language model? So what is a language model? Sorry, yeah. I guess now if you, so this is a model.

Yeah, exactly. So then let's talk about like what is generative AI, right? Generative AI is just types of models that create new data that mimic characteristics of like the training data. So it's like instead of doing a prediction task, the goal is generate something new that's similar to what was in the training data. Images or text, the most popular use cases are images and text. There's also audio and video, which are like more complex. And I think they're a little harder to understand. Yeah, but it's actually...

It's mind boggling. Like with mid journey, it's able to like imagine new image. I mean, you need a prompt, obviously, but it's crazy. Like the output is, is so aesthetically pleasing and it's, it never existed before. It's like something that our minds imagine. Like how the hell does it do that? Yeah, that honestly, even I don't understand. It's a combination of images and text. I mean, through using the concepts that we discussed, but yeah, I don't exactly understand how mid journey specifically works. It's a combination of.

The image. Yeah, but like just the general idea of like, forget mid journey, but even GPT -4, for example, the output it has, it's not so, for example, if it, I'll go back to my first example where I was asking, it's like, my baby girl, I want to start solid foods. It's answer, it's not as if it's copy pasting that answer from like the billions of training data that is found somewhere. Like, I found this Reddit thread that someone was asking the same thing. So I'm going to copy paste.

It actually uses the context in which I've presented the question and then answers accordingly. So it's like, it's like us, like this conversation, if you take all the words, it's a novel thing. It's never happened before. That's what we do, right? How is this machine able to do that? I don't, like that's the magic for me. So yeah, I don't know if I'll be able to answer exactly that. I hope like we have some building blocks that we've built up so far and we can.

(13:48.302)
talk about specifically how chat GPT is trained. There are a couple of more concepts that we can cover there and then we can discuss. So this is model. I think based on what you explained, I'm getting a good understanding of this. Then what is a language model? What is the large language? Because I keep hearing this word LLM everywhere. I don't know what that means. A language model. We talk about generative models. Generative models goal is to generate something new that resembles the training data. Language model. The goal is just to generate text.

that resembles text that was found in the training data. So the very basic function of a language model is to predict the next word given a set of words. So if I give it a string of like, you know, some 10 words, it'll predict what is the most likely next word to come out of it based on what it learned from its training data. That's a very base what a language model does. And you can extend that to...

I started predicting the next word, I can say, predict the next hundred words or predict that that's the token size. That's what we were talking about with GPT. Given a word. You can say anything given it. Yeah. So when you go to chat GPT, you can type in just one word if you want. Yeah. Press enter and it'll generate something. That seems ineffective, no? Like it should be given like a, you think it could work even with a word. Yeah. But obviously the more input the better. The more input you give it, the better.

But all it's doing is like, if you say, sorry, I had one example here. If you have a word like, I don't remember, like this is a blank, okay? Then it'll look at all the past instances in a training data where this combination of words existed. This is a followed by what was the next word there? And look at what is the most probabilistic outcome of that next word based on my training data. That's the first thing it does.

And then if you ask it, what's the next word, again, it'll say, now the context is this. I've put it into my context. What's the most likely next word to come out of it? So what it's doing is trying to predict the next word based on its training data. And this is the way the training data is encoded in the model. And the architecture of GPT -3 is extremely complicated. I have like this slide on it. I cannot explain it to you. Unfortunately, it is too complicated.

(16:10.958)
But I think the key thing I want to emphasize is there are multiple loops and layers of like feed forward network. This thing that here, this is feed forward network. What that is, is this thing. This is called a feed forward network. This is the most simple kind of like neural network where everything is just going in this direction. There are way more complex neural networks. They're called like recurrent neural networks or long short -term memory networks that have more complex architectures. But what...

is happening here is there a bunch of different neural networks that are combined together. There are probably like, you know, like N number of different layers of neural networks. So you're saying that like if you go back to that one neural network slide where you have like the seven eighty four pixels predicting. So with GPT, the level of complexity is so high that it has many of such neural networks and the hidden layers between them is also insanely large. Yes.

And that's how you get to 175 billion parameters because as I said, the starting point for the number of parameters is here and that's actually 617 million because we discussed that there are 50 ,000 vocabulary words and then there are about 12 ,000 embedding dimensions. So that itself is 617 million parameters. And then that's going through and getting multiplied by...

Remember how when we talked about here, each layer was getting multiplied several times. So similarly how this 784 led to 13 ,000. So in GPT, we're starting with 617 million instead of 784. So help me understand this just because it's like mind boggling the amount of computation that is going through this. So every time I'm asking a question to chat GPT, like it must be doing an insane amount of computation to answer.

Yeah, so we need to separate two parts of machine learning. There's training and inference. Yeah, that's what I was going to come to. Is the computation only required for training? And once you've trained the model, then the answers are not very computationally intensive? No. Again, like going back to this example here, the training is the process of finding the parameters. Right. It finds that 150 are the right parameters. That's what training is. And in the case of this neural network,

(18:32.206)
Training or learning is finding the right weights and biases. That's finding the right value for all these 13 ,000 parameters. That's training. Inference is given a new training example or a new example, calculate all these 13 ,000 parameters and output the final value. That's a much simpler computation. Right, but in all of these previous examples, the final value was limited, right? It was either like a concrete, discrete. Yeah.

Yes, orange, yes, no, apple. Or it was like a set of values in the home value price, which could be like between one and infinity, but infinity, but it's still like arithmetic, right? But in case of generative AI, it's, I mean, it's still like a permutation of combination of words, but it's - No, remember it's multi -step at every stage is just predicting what is the next most likely word. At every step is just one prediction that's coming out. So you're saying it's actually as simple as that. It's just predicting the next -

So that's what a language model does. You give it some input text. It takes this text and it says, what is the next most likely word to come out of that? First it does that. Then now that word that it output. It's always a word, like literally it's just a token. Yeah. Then that word becomes part of the context. And then it says now given this entire context, what's the next most likely word? So you're saying to this day, the way chat GPD or chat GPD four is working, it's like.

at the algorithm level, it's only predicting the next word every time. Yes, it's only predicting the next word every time. Yeah. That's the basic language model. There's some reinforcement learning on top of that to input human preferences and stuff for the style of response it gives you. But yes, at every stage, it is just predicting the next word. Given a context, what is the most likely next word to come out? That's the prediction task. And...

That's what the - It doesn't even consider, okay, here's the next four or five words. Because a lot of times your next word might, is not just influenced by the previous words or the context, but you might choose what your next word should be based on what the other following words could be as well, right? Yeah, that's how a human would do it, but that's not how - Maybe that's the next evolution. Yeah, I don't know exactly how that would happen, but right now, a language model just predicts the next word.

(20:50.83)
And there are a couple of steps in this that I wanted to talk about. So how chat, so this actually talks about how GPT -3. Move the mic a little bit closer. This is GPT -3, how it's trained. The output of this. Actually, before we jump into all this, what does GPT stand for? It's Generative Pre -trained Transformer. Or it might be Generalized Pre -trained Transformer, but I think it's Generative.

But the transformer is this type of architecture. It's the model architecture, like how we had linear regression and then there was feed -forward neural networks. Transformer refers to this type of architecture. Generative just means like it's generating text. Pre -trained refers to the fact that it is trained and it has these parameter values already fixed. Okay.

Is that something that OpenAI came up with or like GPT is like a general term, like everyone can have their own? No, they just came up with their own name. So when I hear the word GPT in the wire, it's always to do with the OpenAI's GPT. Like it's not that Google will have its own GPT and Facebook will have its own. No, they'll have different names. And that's actually an interesting question because recently OpenAI has been trying to enforce their trademark on GPT because a lot of people have been...

publishing applications with the name GPT in it and OpenAI wants to avoid this name becoming genericized. Too bad, cats out of the bag. Yeah, I mean, I think there are some legal methods they can use. There's this, I don't know, trademark law is very complicated. There's this thing where if people are using this word in a generic way, then you can't enforce that trademark anymore. So I think Xerox was one example. People started using Xerox in a generic way. It's like I'll...

Xerox this year Airbnb is another one. Yeah, so in those cases you lose your Trademark ability. So they're I read recently their pros and cons because it's a nice to be in a position where your your company's name has turned into a verb like I'll be I'll Google it I'll GP it maybe but I think they're gonna be associated like if I make an application called chaos GPT. Yeah, yeah, yeah, you don't want to be

(23:07.886)
But okay, let's just finish this thing. So this is GPT -3. Chat GPT is one step beyond GPT -3. So this thing here is initial language model. That is like GPT -3, okay? It's what it starts with. And then it does this thing called reinforcement learning based on human feedback. And it comes up with a reward model. What that is is not just...

predicting the next word, but like it's taking human preferences into account. So the humans evaluate a bunch of samples of prompts and responses. And there are a bunch of like, basically they hired like contractors who evaluate like prompts and responses rate. Is this a satisfactory response or not? And that's the second step on top of the language. Language model, all it does is predicts the next word based on the training data and the model.

It just predicts the next word and then the next word and then it produces a string of text. This process, it's called RLHF, reinforcement learning with human feedback. That's like the next innovation on top of language models where they input human preferences into the style of response the GPT gives you. So it's not just about predicting what is the most likely next word, but you have to predict the most likely next word that is like like,

as an output by human beings generally. So you can't give output that's... Help me understand this. So GPT -3 doesn't have that human feedback. No. But is it gibberish that it produces? Or is it like too rude and you need human feedback to like make it more polite? Yeah, it's like either too rude or it's like not super context aware.

Like, is this not the style? Yeah, actually, I don't have a good example of like what kind of response it gives you. But it's not gibberish. No, no, it's not gibberish at all. GPT -3 could very well work as chat GPT. You might not like it, but it's going to be legible. It's not conversational. It's not intended to be because the way GPT -3 is trained is like you gave a snippet of text. It's like that text was in the middle of an article and then it's predicting like the next text from that. That's not conversational. So this process just makes it conversational.

(25:27.886)
That's all. GPT -3 is like normal tech, it can predict the flow of text, but it's not optimized for conversational text. Right, so the innovation with chat GPT was using GPT, which is a language model and make it more conversational, which is what I'm enjoying. Yes, exactly. In fact, it's not, the model itself is called instruct GPT, which is supposed to be like taking instructions and...

fulfilling those instructions. So yeah, but chat GPT is based on that basically. Yeah, so basically that's everything I wanted to cover on language models and AI. I think I just have one or two more slides that talk about now what this means now, how you can use GPT to like build applications and do cool things.



# S1E4
(00:00.046)
now what this means now, how you can use GPT to like build applications and do cool things. Yeah, like very interested about. So like, obviously, I can I've seen chat GPT, I'm paying the $20 subscription. Honestly, I feel like $20 is too little for the value that you get out of it. I mean, we're grateful to be like this, that $20 like we were blessed to be in a situation where $20 seems like nothing.

But you know what I mean. I mean, like, it's good value for money. Like you have a person you can talk to who's like a very smart person who has a great general knowledge about everything. But what are like, and the other thing I want to like talk about is like just the pace at which everything's going on. It just, it seems like it's insane the progress that AI has made just over the last one year. And a lot of people keep saying that it's exponential. And...

like it's hard for humans to process exponential, but what does that mean for our future? Like how, like are we heading into like just all the technologies exist already where you can think of a world where anything you want to see on the screen of your phone or your laptop, you can be sure if it's generated by an algorithm or if it's real. Like I can already see a path to that world. Yeah.

absolutely indistinguishable. Like you, let's say, see a video by a person saying something, there's no way for you to tell if this is real or not. I mean, it's not even far fetched. Like I think in a year or two years we'll have that time with the hyper realistic images that you're seeing. That's like, that's one area, but like what are some other possibilities with this technology? Okay. I wonder cause do you mind if we like,

take a moment to just look at these last two concepts that I have on exactly how GPT is being used in applications. Just understand that for a minute and then let's pause and come back to what are the larger implications of it. So right now we got up to chat GPT. What this thing can do is have a conversation with you. You ask it a question, it answers it and that's all it can do. And it's only doing that based on its training data.

(02:14.574)
It doesn't have access to like anything else. Like, so chat GPT was trained on something like 300 billion tokens from the internet. It's 300 billion words. Yeah. I mean, but the tokens, it's not deduplicated. Like if the word the appeared like a hundred times, that's a hundred tokens. Hmm. Okay.

Yeah, what has it been trained on? Like the internet? Yeah, I mean, so everything, every post that's been written on Reddit, every movie review on IMDB. So OpenAI does not reveal this. And this is part of the criticism of OpenAI is that they're not very open in revealing. Like, yeah, such an irony. Yeah, exactly. That sentence. OpenAI is not very open. So this stuff that we're talking about, like, no one knows if this is how chat GPT was trained. This is the best guess of like researchers. really? It's all close.

Yeah. Why are they called Open AM? I'm curious. Do you know like what does the open stand for? I thought it was like an open source project first. Yeah, it's not. It's not. It's not. 100 % not open source. It's a for -profit company. It has a complicated structure. It started as a nonprofit. It actually got a lot of investment from Elon Musk and a bunch of other people. So it was a nonprofit first and then they transitioned to a capped profit company. What does that mean?

Profit means that like they set a limit, a cap on how much profit the investors can make. It's something like 10X or 100X. I think it's 100X, I don't remember, but that means if I invest a million, at most I can get back 100 million. If there are more profits beyond that, that goes back into the company. okay. Interesting. So non -profit just means... Are there other companies that follow that model, that popular companies that you know of? No, I don't know of any. This is the first one that I know of. So yeah, they created this new structure called CAP.

profit because they realized that like the funding they were getting through being a nonprofit was not sufficient for like the training that they had to do on everything. And then they became capped profit. And then yeah, Microsoft then invested heavily in them. And Microsoft now, I think owns 49 % of OpenAI and the other 51 % is from the original entity. So it's a weird complicated. No one knows what it's been trained on.

(04:24.654)
It could be everything that's ever been produced on the internet. There is actually evidence that OpenAI itself doesn't know what it was trained on because in some papers they released, like they used words like, this thing was inadvertently included in the training data. And like people were like, what does inadvertently mean here? So, no, I think they mostly know it, but they, yeah, they don't release it. It's also unclear what the legal and ethical boundaries are of what they trained it on.

that's extremely unclear. Right now, for example, a lot of companies are trying to lock down access to their data recently. So Reddit was a huge source of training data for OpenAI and recently Reddit locked that down and they said, now it's against our terms of service for you to use Reddit data to train your machine learning models. And instead now they're offering a paid service where they say, you can use our data to train your machine learning models, but...

You have to pay us for it. But what's done is done. Now that GPT -3 has been, like, you can't remove, actually, that's another question I have. Can you, once you have trained the algorithm, and let's say there's some legal complications, say that, hey, you need to ignore all of this understanding. Would it, like, update its vector map? No. I think realistically what would happen is if that happened, they would just say, sorry, this model is illegal. Now go train a new model that's legal. Right. Yeah. So that - But in this Reddit situation, they can't do that with GPT -3, even though it's been trained on.

It's kind of a gray area. Like, I don't know. Like legally, it is a gray area because it's publicly available. This text that's on Reddit, like anyone on the internet can access Reddit. Wikipedia, Stack Overflow is a big one. So all these were used as sources for training data. And then those people feel like they're not both like Stack Overflow and Reddit and also the users behind those websites. Like...

It's kind of unfortunate that like their work is now being used. Yeah, being monetized in a way that they're not getting anything out of it. I imagine this is going to increase and become a huge problem. Like with mid journey, for example, I'm sure mid journey has also done something similar like trained on. Like I think that underlying technology that powers is stable diffusion, which has trained on like a billion images.

(06:41.646)
And it's not clear what the copyright status is also of those images, right? Yeah. Like mid -gen, you can say photography in the style of some famous, like Lebowitz or something. And it'll do that. That person's not going to get any money. Like celebrity images can be generated and like celebrity voices, whatnot. Yeah, I read recently there was an artist called Grimes. I don't even know who this person is. They said that, if you want to generate AI -based music in my voice.

go for it and share 50 -50 or so I don't know what the... yeah, let's finish this thing and then we'll come back to this. So the thing I was gonna say is okay, here's an example of how, okay, sorry, before we get to this, let's talk about what is the limitation here right now? What can I do with this? This model was trained on some 300 billion tokens of text. The...

cutoff was sometime in 2020 or 2021, I think. yeah, because sometimes when I ask you the question, it says that I don't know anything after. Yes, exactly. Which is unfortunate. A lot of questions I have is like with more recent stuff. yeah, so that's exactly what we're going to look at. So like now all this does is it created a language model based on the training data that it had up to 2021. But now what if I want to do stuff with it with more data that I have? Like how do I do that? How do I? And now everyone is, that's the,

Currently one of the hottest opportunities right now. So chat GPT does not know how popular it's got in some sense. No, it doesn't. That's so funny, no? It has no idea. It doesn't even know what chat GPT is. Yeah, exactly. That's another interesting thing. Yeah. So, but I think one of the biggest opportunities right now, what everyone is trying to figure out is how do I connect chat GPT to some text that's more interesting to me than what it was trained on?

And it could be like my own company. I have my internal database at my company and I want to answer questions based on that. Or like maybe you have your own - Like health data. It's like, Hey, look at my Fitbit log, everything on structure data. Cause I have my Fitbit log for the last five years and like suggest some things that I could improve that maybe Fitbit cannot. So let's try to think of a simpler example. Cause Fitbit logs is not typically what I would call it.

(08:59.342)
text data that's like very structured data. But think about if I had like a database in my company. Actually, one example I saw recently was a guy that built a chat GPT based app that would look at the history of all Lex Friedman podcast transcripts and answer any questions based on that. that's a good one. Yeah. That guy has like really like academic people on his. Yeah, exactly. So but he has like hundreds of episodes. Each episode probably has like tens of thousands of words in its transcript.

How would you even build a system like that could interact with that level of text and find the right? Because remember, ChadGPD has a context window, limited. It's like 4 ,000 tokens. So I can only put 4 ,000 tokens of text into ChadGPD. Actually, could you not, because I don't know much about this, maybe it's a stupid question, but take the ChadGPD model, retrain it again with additional data, and that additional data would be the Lex treatment transcripts. Is it not possible for any normal person to retrain?

these things? It is possible, but that retraining actually doesn't give it new knowledge. That retraining would mostly just give it new ways of answering questions, a new style. The way to give it knowledge is to connect it to an external database. Retraining would be like a prohibitively expensive process every time. So yeah, suppose it does even give it new knowledge retraining.

It's ridiculous to say that I need to train a 175 billion parameter model over and over again, every time I wanted to have some new knowledge. So that's not gonna scale. The way to do it is you connect GPT with external knowledge databases. And that's actually one of the recent evolutions that's happened and that I wanna talk about. This is a graphic from one of my colleagues actually, his name is Vikash. He works at my company and he's been writing a lot about like AI.

and LLMs and he created this graphic of how you would create a question answering system. So think about this, like you have a question about some private document that you have. Okay. So what's happening there first, like let's look at this box. You have what's called a vector database. We talked about like words to vectors, right? Embeddings. Embeddings. Yeah. That's exactly what's going on here. First, what you do is you create a vector storage of your documents.

(11:19.662)
In this case, I assume documents. Yeah. I've been hearing a lot about these new databases that specialize in vectors. So like pine cone, have you heard of pine cone? So pine cone is probably the most popular. It says here example of pine cone. Yeah. So pine cone is probably the most popular vector database right now. There are a couple of others. So these are specialized database instead of like relational, like row wise stories. Yeah. They do embedding. Exactly. And we talked about embeddings, the word vectors. So they're like the NVIDIAs of the databases. Well, NVIDIA is...

processing, not storage. Or any of them public, I want to buy the stock maybe. Pinecon recently announced and recent Horowitz invested a billion dollars or something in them. Yeah, good for them. It was huge. Anyways, go on. So this box? So first what you do is you take your entire knowledge base, all your documents, in this case it could be your personal notes, your company's database, and you convert them to embeddings. OpenAI has an embeddings API.

and you upload them all to a vector database. Okay. So that's the external knowledge base that you have now. And when you, so, so, sorry, I keep interrupting you, but I just want to clarify. So the advantage of doing this is you've translated into a language that these models can understand, which are embeddings. So the language that these new models understand are embeddings. Yes. Okay. And also embeddings can have mathematical operations on them to understand similarity. And also the storage is more optimized. Okay.

It's because it's designed to store embeddings. Yeah, exactly. So when you ask a question like blah, blah, blah, whatever, like say suppose this is the Lex Friedman example, right? Suppose these documents are all Lex Friedman podcast transcripts. Suppose your question is like, hey, what did Lex say to David Deutsch or something about physics? Right. Right. So then the question gets converted to an embedding. Right. And then you go and query the vector database.

and you find what are all, you do a vector similarity search for what are all the documents that are similar to this query. So you can do vector similarity search because like vectors are mathematical objects and you can look at what is the distance between any two vectors. So you can say, given this vector, give me the 10 vectors that are closest to it, that are most similar to it. So given this question, I can ask for the 10 vectors that are most.

(13:34.126)
similar to this question. Basically, it sounds like with this whole vector logic, with Boolean, the advantage was that you've started to doing arithmetic on language. That's what it sounds like with vector you're able to do. You're able to manipulate language without actually knowing what is in understanding the meaning. But you're able to abstractly manipulate it and then come up with a novel. And originally, we were talking about words as vectors. Now we have documents as vectors. OK.

So now it will retrieve the five documents that are most similar to your question. So you ask it a question, you say, tell me what Lex said to David Deutsch about like physics, some random thing. It'll look for what are the five documents that are most similar to it. That's what it creates as the context. And then it passes that context to the LLM, like Chad GPT. And now the question that Chad GPT just gets is like, given these five documents and this question,

answer the question. That's something you could directly paste into chat GPT right now. But the thing is, if you connect it to an external knowledge base, you cannot give it the entire transcripts would be like, you know, like thousands of pages and that can't go into chat GPT. So what's happening is those thousands of pages are being stored as a vector database and you can efficiently retrieve.

whatever is most relevant to your question. Why wouldn't ChatGPD just build something that makes this whole process easy? Yeah, they do. It's called ChatGPD plugins. OK. Yeah. What are those? It's exactly this. Basically, anyone so I can build a plugin to ChatGPD. I don't have to do all this vector business, meaning like I'm... No, you have to as the plugin developer if you want some... So the user doesn't have to. Yeah, let's say I'm the lay user, the lay person, and I want to connect ChatGPD.

to like my own private data base. Yeah. Where's your private data? No, forget database because database itself is something technical. Yeah. Like I have a, I don't know, like my grandfather has a bunch of like, like has a diary that he's been writing in for the last 50 years, let's say. Yeah. And it's in digital format. Yeah. It's in a Word doc. Yeah. I don't want it to be released anywhere. Yeah. But I want like, to be able to tell me stuff from that diary. Yeah. So how can I do this as a lay person who doesn't understand

(15:52.974)
vector business, like I don't wanna use the word vector, how can I achieve that? Yeah, you can't, but the app developer, so if the diaries are stored as Microsoft Word documents, Microsoft can release an chat GPT based application that does this for you. And it says, hey, all you gotta do is like click this button to connect your Microsoft Office account to chat GPT and you can ask any questions of it. So the first step is the app developers are gonna do this. So Microsoft, Google,

Slack, Discord, WhatsApp, all these applications that have data in them, that have documents, that have knowledge bases, they all have to think about what is their business strategy, what do they want to build, and they're probably going to build these applications, and you as an end user can then connect, depending on where your data is. If your data is in Google Docs, then you can probably connect to Google and whatever application Google built. We talked about Notion. Notion has its own AI.

So yeah, it depends on where your data is. And this is still territory that's extremely unclear what the business strategy will be for these companies, how they will develop. But if you're an independent app developer, you can do this. So this applies not for users, this is for app developers. If you want to develop an app that users can use, so you make this podcast, right? Docents. Suppose you want your users to be able to interact with this Docents podcast through

a natural language interface, you could make this app. You could upload your whole transcripts to a vector database and make an application such that users can say, hey, tell me what did Nikhil say on Dawson's podcast about vector databases? And they get the answer. So yeah, this stuff is what app developers can do using GPT. OK. This thing is an architecture for a chat GPT plugin. Yes, for a chat GPT plugin.

or more generally for a language model to interact with an external database. Right, so again, if I step back and then go with our high level story, like in the evolution of AI, from classical programming, we went to classical machine learning, and then from there we went to neural nets, and at every point we were hitting some walls, we're finding solutions. We can share. Yeah, we'll share this.

(18:16.718)
And then we're hitting a wall and then we're finding new solutions. And this, it led us to generative AI, which is what has fascinated us, which is the reason why we're here. And Shad GPT is the start, but this is another innovation that's come on top of it, which is adding plugins and giving that language model an external source of knowledge. Yes, exactly. Because Shad GPT doesn't have any knowledge other than what it was trained with. Right. Right.

What are some other such innovations that are happening on? Okay, so I want to talk about one last thing, which is like this is just giving it external knowledge. There's also giving it whole other external capabilities and tools. Like, for example, chat GPT is a language model, but it's not good at math. It's not good at like programming. If you ask it, what is 5033 times 3044?

probably won't give you a good answer to that. It is not. Because the next word prediction type thing. Yeah, exactly. But chat GPT doesn't need to answer that question. All chat GPT needs to know is that, hey, this looks like a math problem. And to answer this question, I'm going to use a calculator. That's what it needs to do. And then all it needs to do is figure out what are the two numbers that I need to plug into the calculator, plug them into the calculator, and get the result for you. So that's actually. I have a question there.

You said that chat GPT, the only thing is doing, even though at our level, it looks like it's a fascinating thinking person, like in reality, the only thing it's doing is just predicting the next word. Yeah. Right. That's all it is doing. Yeah. Like in reality. Yeah. Then how is it going to do all this that you describe, even that, that, it looks like it's a math problem. Like that seems like it's more abstract thinking. It's not just predicting the next word. That's where language model meets prompt engineering. That's where you have to develop the right prompt.

to get the right response. So the right prompt here could be like, hey, what tool do you need to answer this question? Imagine if you just put that prompt then - No, but from how you said it, you made it sound like ChadGPD is gonna figure all that out for you. So you just say, what is 18 ,000 times 1 ,544? And ChadGPD will figure out, okay, this sounds like it's a math question. It's only in this math question, to solve this math question, I have to invoke a calculator. So this sounds like thinking.

(20:39.022)
yeah, but it's not predicting next word. Sure, but I'm saying this is a program that you have built where Chad GPT is the central part of the program and you, the program. I see what you mean. You're saying you're still thinking from an application developer's point of view. Yeah, exactly. Yeah, yeah. Chad GPT is not doing this on its own. And Chad GPT will never be able to do all like thinking on its own. I'm not sure why that's relevant. I should use words like never, but you know what I mean?

But I am like, OpenAI could easily release a new thing called Agent GPT that does this. So I'm not sure why it's relevant whether Chat GPT can do this or not. Like, yeah. Most likely that's what's gonna happen. OpenAI is probably gonna release something called Agent GPT or some version of that. There is an actual agent that can do things that calls Chat GPT and asks it specific questions. So I would ask Chat GPT given it asks. That's a good conversation to have because I'm...

How would agent GPT work? Do you have any insight? That's the last example that I have here. It sounds like the next evolution. Our discussion has been leading into this breakthroughs and getting more powers. With plugins, it gets more power. But when you say agency, you mean a sense of agency. Right now, from my point of view, from a layperson's point of view, the only thing differentiating a human from a...

like a machine is like a sense of agency. Like there's like, like we're not just in a meat body, right? Like we have a sense of agency. There's like a soul that we have in our meat body, like, and then we do in the world. Like where is the machine, even though let's say someone creates like in 10 years from now, like, like using whatever new breakthroughs in biology or whatnot, like a biological machine with like chat. Yeah, like some Westworld kind of thing. Like it, how, like it won't have a soul like we do and have a sense of agency, but.

the way you - I don't know if those two things are related, like having a soul and agency. I could give a program simple agency. I could just say like, if I give a program access to my email account and say, hey, you can write emails, that's agency, but that's not a soul. Like it's just simple forms of agency. Suppose I create a chat GPT that connects to my Gmail. I say, hey, every time you get an email from Piyush, like just take that text.

(22:56.878)
maybe look up some knowledge base I have and write a response and reply to Piyush. That would be an agent. Maybe I'm using the word agency wrongly, but just the way you were describing the thought process earlier, like, it looks like this is a math problem. Yeah. Maybe I should take like two numbers from it and you should use a calculator. But I can extend that to the same example. I can say, look, if I get an email from Piyush and he has a question, figure out how to answer that question.

and answer that question, use the tools you need. Yeah, but you're saying all this very matter of factly. Like this is scary and amazing stuff. Like at the same time, like you're, I don't know, maybe because you're in this world, you're a product manager working on AI from, but from my perspective, this is scary stuff, man. Like I don't know, I don't understand how matter of factly you're saying it. It's like this, this is thinking, like you're thinking. Yeah.

I think so the level of scariness depends on like the level of empowerment you give it, right? So if I'm saying I give it access to my emails and I give it access to write emails for me. That's where the agency comes in. Like how do you know you'll stick to like, like that's the agency I mean, like the way you describe it, it sounds like it's like, for cause.

It sounds like you're generalizing that agency when you say that, okay, I'm going to give it a math problem and it's going to start thinking. It sounds like it's a math problem. Yeah. And I need to do this, this. Yeah. Then you're again, going into like the rule -based world. The rule is you can only do, you can have agency as long as it's a math problem, but someone's going to come and say, okay, well, let's remove rules out of it. Well, but I'm saying you define what are the things you connect it to, right? Like,

What are the tools it has? Yeah, exactly. What are the tools it's connected to? So that's how this actually let me go to the next slide, which is the last one, which is exactly about this. This is a system called Jarvis developed by Microsoft in collaboration with props to the branding team. Collaboration with hugging face, which is the biggest like open source library of like machine learning models. It's called hugging GPT. What it does is it uses a centralized

(25:03.374)
language model agent to find, to take your question or task and to break it down into like, what are the right tools that I need to use to find, to do those tasks and then it does those tasks. So here, let's take a look at this. Hugging GPT? Because it's called Hugging Face is the company. It's an open source like - That's a nice - Project that just has a repository of like models and this is hugging GPT. So -

Task is, can you describe what this picture depicts and count how many objects are in the picture? Okay, that's the task that comes in. Then first thing is the language model does this task planning. It figures out like, what do I need to do to achieve this task? And then the second thing is it translates that into model selection. So Hugging Face is a library of like machine learning models. They have a model for pose detection. They have a model for like image recognition.

They have a bunch of different ML models and they might even have a model or a calculator tool. In sort of models, you can think of it as tool selection. It might have a calculator tool in there. So it goes and selects what is the right tool I need for which of the tasks. Where does it select the tool from? From the hugging phase? In this case, we've just connected it to this set of tools. Hugging phase has a list of set of tools, but abstractly, you could connect it to whatever tools you want. But you would always control what...

tools you give it access to. And if you give it access to Gmail, you could control, do I want to give it access to read my Gmail's or also write Gmail's? And if you give it write access, that gives it a lot more power. So what it's doing is it's finding like a set of different tools. It's breaking down the task into, see, it says in this case, what this picture depicts and count how many objects. So first it's breaking down, it's like,

I can describe it as herd of giraffes and zebras grazing in fields. So for that, it needed a model that translates text to like captions. It figured that out that that's the first thing I need. Actually, can you like based on all that we have discussed so far? Yeah. Can you like just based on our discussion, help me understand how that happened? How did it describe text from that image using all the models and the evolution of AI that we have discussed so far? So first, it took this text that says,

(27:26.222)
What does this picture depict? What this picture depicts? And it figured out what is the out of the tools. So first it had to break down the picture into raw pixels, RGB pixels, right? There's first, let's say it process the text first before it process the image. Yeah. It process the text and it said it needs a model that can do image description. That's the first thing that I'd figured out. Then I went to hugging.

GPT and look, it figured out that look, I need this model called image captioning. That's the model. Then what this model does is it takes this image and it breaks down those RGB values and it gives a caption. And the caption returned is a herd of giraffes and zebras grazing in fields. But the thing is these are all specialized models. They're not general models. This model, all it does is it takes an image and gives you a caption. But here is like the central brain.

or like the central, yeah, I don't know, brain of the system that's doing this coordination, that's figuring out what are the tasks that need to be done and it's selecting what are, so it's like a manager in a company. Imagine you have a company and you know, like there's a - That's exactly what I was thinking. It's a man, yeah, this is a high level thinking, high level planning, high level thinking. Exactly, it doesn't know how to do like image captioning. It doesn't know how to do like object detection. But that's what managers are supposed to do, like they're a delegate, like -

Yeah, like it's in some sense, like we're as employees, we're all like APIs. We're all at different levels. Like the more higher level you are, like the more complex tasks you can do. Like a CEO at his level will call an API, like his VP is like, hey, like go make this stuff in India for me, like create iPhones in India. Very complex tasks. So that's actually what this is evolving to now. This is becoming a high level manager.

and it's able to break down the next level tasks that needs to be done. And all you need to do is connect it to the right tools or models that can do that next level breakdown of tasks that it needs to do. And if you connect it to this hugging face library that has all of these open source models. That's insane. You're saying it so matter of factly. I think you're too close in this world and you've been talking to a lot of people who are too close in this world.

(29:45.87)
I'm 100 % sure when you speak to most lay people, this is insane. Like this is going to take away everyone's job. Well, I shouldn't say hyperbolic like everyone, but you know what I mean? Like this is going to a lot of jobs. Yeah, it's very question. Yeah. I don't know if everyone's jobs, but I would say already right now for engineering, I think is software development is pretty heavily hit where I give it a specification, like write a program for me that does X, Y, Z.

it can act as like a software developing like tech lead or architect or manager and then call the models that will develop like what are the sub programs that have to be written, write all those scripts and it could increase engineering efficiency. I don't know what ratio one is to two at least, but could it go to one is to three, one is to five, one is to 10? I don't know. Yeah, it's like the exponential curve thing, no? Like we think like we humans like from an evolutionary point of view, we don't.

think exponentially, but like if you take the progress, which is exponential in this case, it's going to increase the order of magnitude in no. But I think this is the key innovation now with Shad GPT. What people have found is that it's not the purpose of this type of language model is not just to do question answering, but to serve as like an orchestrator of like different tools. And given a task.

It can do things like break down the task into its sub components. And I've been given a set of tools. It can identify what are the right tools that can do this task for me. And we already have like a huge set of specialized models. There are many are open source companies may have many closed source models. And this you can set up an orchestration framework where I can get a task, break it down, go find the right tools to do the task, execute those rinse and repeat. That's what.

these tools like auto GPT and baby AGI that they're doing right now, that's leading to what people are calling artificial general intelligence, which is this engine that is just like able to like generally do any task that's not like a specific or specialized task. Yeah, like, yeah, it's crazy. Like, like even in our discussion, we started with a simple house prediction or determining if it's an apple or an orange. And it's come to

(32:07.218)
Already like in 2023, where it can figure out and do a lot of fast. So actually the other thing I want to talk about, I remember like when we were talking on phone, you mentioned that you believe that this is the iPhone moment. And that really struck with me. Like, can you help me understand what do you mean when you say the iPhone moment and why do you believe that this is the iPhone moment?



# S1E5
(00:00.078)
I remember when we were talking on phone, you mentioned that you believe that this is the iPhone moment. And that really struck with me. Can you help me understand what do you mean when you say the iPhone moment and why do you believe that this is the iPhone moment? yeah. First, I just want to clarify. I didn't invent this terminology. It was the Nvidia CEO that came up with this terminology. He said we're going through an iPhone moment right now. And so let me say why I think he said that and why I...

believe in it. So what was revolutionary about 2007, the iPhone moment, was that there was a shift in the fundamental interface we use to interact with businesses and services. Previously, everything was based on desktop applications or often non -internet -based. It was like, imagine I've had to book a hotel or call a taxi. I had to make a phone call or go online on my computer. And with the iPhone, there was a change.

in the way I interact with the world around me, which is through this device I have in my pocket. I can press a button and it enables completely new use cases. Like imagine I'm standing on a road and I need a taxi to come to me and pick me up and take me where I need to go that did not exist. That was really magical, right? Like Uber was magical. Exactly. Or like Uber Eats or Swiggy in India, like those kinds of things where.

Yeah, I had such a pain like where in India, especially like explaining to someone on the phone what my address is, is like, I think I increase my last time because of Uber. And let me explain why I say that. Because one of the back when Uber launched, I was in India and in Bangalore and you know, Bangalore is infamous for its taxi system to be based on negotiations and not like a fixed price. Every place you need to go, you have to negotiate the price. And it was just the worst thing that I had to engage in every morning. I'd be like, okay.

how much for like that building. Cause I was, I lived very close to my office, but still not walkable because it was very hot and whatnot. So they come to that building and that guy would be like a hundred. I'm like, it's literally that building. Like, this is insane. He's like, no, that's like whatever. And it wasn't, you're saying it's just Bangalore. Maybe it started that way, but it was Hyderabad. I lived in Bombay and Hyderabad. Bombay, like the one good thing about Bombay is like, they still like, I mean, even before Uber, they were.

(02:23.693)
No, actually, I'll tell you the worst thing about Bombay is in Bangalore, it's a negotiation, right? In Bombay, it's not a negotiation and they just say yes or no. So if I say I want to go here, that's a really good point. That's another problem. Like the one problem is the pricing ambiguity. I prefer the negotiation because in Bombay was like I would go to a guy, he would say no. Instead, just open the conversation with like how much you want. So anyway, I think I get your point. Like iPhone, the iPhone moment.

enable all these businesses to come out because everyone had access to a technology, which was in the palm of their hand. It had mapping services and internet. Remember that famous thing by Steve Jobs, the way he launched the iPhone. It's an internet music, iPod, and then he repeated that. An iPod, a new phone, and a revolutionary internet communications device. Yeah, that is one of the most amazing product launches in all of history.

But the key point is that there was a new interface, a new way in which people were interacting with businesses. So if you were a business, let's say you're Amazon, okay? Like originally, the way in which people interacted with your business was they logged onto their laptop, they went to amazon .com, and then they transacted with your business services. Now there's a whole new interface. I have my iPhone.

And what it needed for you to do is you need to develop now an iPhone application, a mobile application, so that I can interact with it on my preferred way of interaction. Because now, like, I no longer want to log onto my computer every time I want to order. Or I don't want to call anyone. Exactly. Yeah. So I think that's the key shift that happened is there's a new method for consumers to interact with businesses and services. Right. So I think the...

When people say there's a new iPhone moment now, what that means is that there's now yet another new way in which consumers want to be able to interact with services. So I want to be able to interact with Amazon, probably not just through the regular Amazon app UI, but I want to have some like natural language interface to interact with Amazon. I want to tell Amazon that, hey, like, you know, based on everything you know about me,

(04:46.285)
based on maybe you and I had an email conversation about like some jeans, you know, we've talked about easy jeans. You actually recommended these easy jeans to me. I'm wearing them, I love them. Like what if that was somehow captured in a knowledge base and I could just tell my AI that, hey, like go order the jeans that Piyush told me about. That's how I wanna interact with computing systems and with businesses in future. I don't wanna have to go to Amazon or to the Uniqlo website.

and figure out what is the, I have to go to my email, figure out or remember in my own memory, like what you told me and type in the name, easy jeans and get that. Now it's like, I want to have a connected natural language interface where I can say, look, you told me about this thing. I want you to get it. You mean like a life companion of sorts where they're context aware about all the happenings in your life.

and they can like do stuff for you, like an assistant. You shouldn't use the word companion, maybe. Yeah, that's different. I think that is going to be the new interface, like because we talked about chat GPT, we talked about access to knowledge basis. Right, right. That's already coming. We already have so much of our knowledge stored in email. If I combine my Gmail, my WhatsApp conversation history with you, plus if there are some way like my phone calls with you and these interactions could be recorded and stored like.

There's just such a wealth of information. And if that is a ready -made context for me to have interactions, then the interactions I'm going to have with businesses are totally different. I'm just going to say, okay, let go order the thing Piyush told me about. And are there examples of any such early businesses that you know of that are using this shift in interface as you describe it or like the paradigm shift from. So right now I think what people are trying to do is convert.

existing interactions into natural language interaction. So that's what chat GPT plugins does. So chat GPT recently or open AI about a month ago released a service called plugins where you as a business owner can provide a plugin to chat GPT. And one of the original plugins they came out with were kayak, Expedia, providers, open table, you know, the restaurant bookings, Instacart.

(07:06.765)
Actually, Instacart is something Rukma and I used recently. So we keep our shopping list in Google Keep. We have a shared Google Keep. Yeah, we do that as well. Yeah, yeah. We can both add things to our shopping list. And then literally we copy pasted that entire shopping list into Chad GPT using the Instacart plugin and said, hey, order all these items. And it automatically generated an Instacart order. And in fact, it...

asked us for some ambiguities. It said, hey, you asked for like oranges. Do you want this type of orange or this type of orange? And then it was like, you wrote yogurt, but like, what is the quantity you wanted? Yeah. Blah, blah, blah. And then it got that information and it immediately generated an Instacart order with everything. And then all I had to do is click, like approve to buy or like cancel. And over time that could learn.

My preferences, maybe it just already knows that when I write apples, that means I like Fuji apples. That's my favorite kind of apple. When I write yogurt, I mean like whatever, XYZ yogurt, it saves my preferences. And then my interaction with Instacart is extremely simplified now. I don't have to like go and select like these detailed like options. I just write a very simple like Google keep list. I say I need apples, yogurt.

potatoes, onions, whatever, and it knows exactly what I mean by all that. It saves my preferences. So what I'm hearing you say is that one of the things that's gonna happen is you have the existing way of doing things and it's gonna remove that friction and it's gonna make it more easy to do these things, right? Like make it more natural language. So for example, right now you have your shopping list, you go on Instagard, you do all that, that whole process, that friction is removed and it'll all be done automatically and you can sort of rely on that.

interface to take care of everything. If there's ambiguity, like figure out from your preference, what kind of orange you would like and all of that. I think it still remains to be seen exactly how this will evolve. Like are my preferences going to be stored in Instacart or will I have my own personal AI where I store my preferences? Yeah, I'm not so much bothered about like how the how it will be implemented technically. I'm like sort of envisioning what our lives will look like with this.

(09:20.717)
and I can see what our lives will look like. It's going to be - Have you seen the movie Her? Yeah, I love that movie. Yeah, I think like it's - Actually, so it's a great segue to my next question. Like movie Her is a great, great, great segue. It's okay. This, the way you describe it is how existing businesses or existing use cases will transform. But what I am curious to know from you is what are some new things that will emerge because of the new capabilities of these technologies? Like businesses that weren't possible before.

or ideas that were not possible to be executed before that now can be executed because of like this powerful technology we have. And then we discuss the evolution of this powerful technology, like AutoGBT being like this manager that you have access to. Like, hey, do this for me. Okay, like I'm anthropomorphizing AutoGBT, but it's going to be like, okay, this is the highlight task. Here's how I'm going to plan to do this task. I'm going to break it into sub tasks. Here are all the tools I need to achieve these sub tasks. And it's like a genie, man.

I mean, this is like the billion dollar question. If I knew the answer to this, I'd probably go be building this product right now and I wouldn't be sitting here. But you're in this industry, like, do you know of like some ideas that people are building that use cases that have not been possible before? Types of businesses that have not been possible before? Yeah, to be honest, like, I think it's still very early and I cannot think of any such use cases right now that are.

popular, chat GPT would be one example. Right, mid journey is an example. Mid journey and chat, but they're like very base level examples. They're not. They will enable these businesses. Yeah, they will ideally enable like in future businesses. And I've been trying to think about what are some businesses that would be enabled, but yeah, I think there is no clear answer to this right now. If there were, there just can't be at this stage because it's still like early stages. If people knew the answer already, like that would,

already be there right now. The other question I had related to the topic that we're discussing right now is, like we have discussed this previously, like an ideal, like one of the things that we always talked about is like a life of a solopreneur, right? Like a solopreneur is a person who like has a product or a company is basically able to fund their life and lifestyle with a business that they are a sole employee of, meaning like they run the business. It's a single employee company, right?

(11:42.797)
And it sounds like these technologies can really enable that vision, right? Because you can make it easier to code. If you're thinking of an online business, it can make it easy to code. Like there are all these code applications. You can call all these APIs with AutoGPD. You can almost use it as like a tech lead and whatnot. That's the one side of thing. The other side is it sounds like as there's more and more development in these technologies, like these interfaces getting more and more powerful. And like these API calls are...

getting more powerful. So it sounds like any idea that you have will sort of be short -lived or you'll always live in this existential crisis is that some API is gonna basically generalize your problem. Like, let me give you an example. Like one of the things that I've been experimenting with with mid -journey, because I find all this stuff very fascinating, is have you heard of this thing called Dream Booth? No. So mid -journey is an application where you can basically create any image that you can imagine. And you can imagine that with a prompt, you write the prompt and imagine.

But let's say you wanted to imagine yourself in different situations, like Nikhil in a space suit or Nikhil, like, I don't know, wearing whatever, like a 17th century costume. But Journey cannot do that because it's not trained on your specific face era. So Google came up with this research and then like an open source product called Dreamboot, where you...

train the stable diffusion model on your selfies or like there was this thing called deep dream earlier, right? Yeah, maybe there are other products similarly, but the idea is that you create your own version, right? So there are a lot of businesses that are coming up with this, like a lot of, I think you were the one who actually showed me, you shared this guy's Twitter stream about this business he created where he was headshots. I was actually very inspired by that, like this whole thing.

my wheels started turning, I was thinking about solopreneurship, because that guy is basically - AI generated headshots, yeah. A solopreneur, right? Like what he's doing is basically he's taking people's selfies and then he's creating a AI generated headshot, which is an amazing business. All of us are on Zoom, we want like a nice professional. It costs like 500 bucks, that guy is doing for 30 bucks. And like, it's like MP3 versus Vave, right? MP3 gets you 95 % of the quality and no one cares about that 5%. And it's like 10, like a 10th of the storage. So it's a 10th of the cost. But Adobe, your -

(14:00.301)
ex -employer is working on this protocol Firefly, in which they're sort of generalizing this whole thing. Like basically you'll input a bunch of pictures and then you'll give a prompt, like do this with these pictures, like this person. So that kills all the ideas with this concept, right? And then let's generalize this. It sounds like it's like an ultimate API contest where like there's, everyone's trying to build like this generalized powerful thinking thing.

where you basically prompt, here's what I want, and you'll get that. So my question really is like, here's a dream of solopreneurship, but here's this fear that like these powerful tech companies with like their GPUs and their computational power and the direction in which they're heading is like more generalized problem solving. Like, how do you think about this? Like I'm in conflict. Like, is it like a futile effort to even approach this part? Unless you're...

like thinking of getting acquired, like build something in the short term. But what if you want to do like a meaningful pursuit where you want to dedicate the rest of your life? Like I have like 25, 30 years more of more work remaining. So, sorry, are you saying, I'm trying to understand, are you saying that the big companies are going to take over all the popular use cases and there will be nothing left for - Yeah, I fear, like that's my worry. Is this the right way of thinking it? Like I'm telling you what I'm thinking through and I want you -

I want your opinion on this. Is there a right way of thinking about it? I think it depends on the use case. It's very possible that big companies will dominate because one of the things we discussed is limitations of training data. One of the main ways in which your model is more powerful than someone else's model is because either it has more training data or it has more compute. More compute meaning more parameters, more complex model, et cetera.

Training data is increasingly getting locked down, I think. In fact, one thing about Adobe is this guy that I listened to, Ben Thompson, I don't know if you know. Strategory. Strategory. He talks about this a lot. He did an interview with Adobe's chief product officer, Scott Belsky. And one thing they talked about was copyright violations and image generation models. And Adobe was making, Adobe is...

(16:23.181)
very much doubling down on their model Firefly being like a safe alternative to mid -journey because mid -journey is not safe. Who knows what training it has been in. Exactly. You might get in legal trouble. Yeah, in the sense that it's legally not safe. But it's not clear right now whether the... So you're saying... Sorry, go ahead. I was saying it's not clear right now whether the legal standard should be applied at the layer of input or output.

That itself is not clear. Like if I take some, say, you know, Marvel, okay, as an example, can I take Marvel movies and images as input to my training data? Is that valid or not? I don't know, because current copyright law does not specify that. Our current laws are not designed to understand like this technology. Yes, exactly. Or they were written in the time where like technology like this didn't exist. It's very clear that at the output layer, it's prohibited. If I start outputting images of Iron Man,

Yes, that is very clearly prohibited by copyright law. I cannot do that. That is clear. But at the input level, it's not clear. And actually, what Ben Thompson was saying is that companies like Adobe are trying to argue for a more restrictive version of the future, where they're trying to say that, hey, your input has to be heavily restricted. You cannot even get... Okay, help me understand this because my knowledge may be limited because of what I understand from this. But isn't the problem with these models...

like the problem with internet in general, like once they've been trained, the cat is out of the bag. Like once you've trained a model on the internet, it's done. Like we have sufficient data that's already been generated on the internet to like have these models already trained. Like mid -journey is there. What are you going to do? It exists. And like you can copy, like, okay, mid -journey is a closed source, but there are like open journey, which is an open source mid -journey. Like chapgpd for example, right?

I think the question is not about the model. The question is, can you commercialize the output of the model or not? That's the main question. As an output of this model, I got a video or an image. But you yourself said that, like even OpenAI doesn't know what it's been trained on. It's like there's the problem of explainability. Yeah. So as you, like, is there a way right now to determine from the output of a model, what training data was included in that model? No.

(18:41.679)
There's not, but I think we need to answer, is there a legal need to even clarify that question? But because from what I'm hearing you say, then based on my discussion, you're saying like one possible competitive advantage you might have as a solopreneur or any business might be your training data, right? That's what companies like Adobe are trying to argue. Actually, Adobe is trying to argue that, hey, like you need to train only on legitimate data sources. You need to train on...

like stock images or non -copyrighted images. Like if you train on copyrighted images, that's not legitimate. That's in Adobe's interest to make this argument because they own a lot of like stock images that they can train on. And mid -year it doesn't. Yeah, I know we're talking specifically about images because of the example I used. But the same applies to text. Like if I train on text from blogs, books that are copyrighted,

Is that a copyright violation or not? Like no one knows. Yeah, it's just the way you describe it. Let's say it does come into fruition. It sounds like a better version of the solution will be trained on everything. A suboptimal version of the solution would be restricted in its training. And eventually I feel like our tendency would be to opt for the better solution. We'll figure out like the laws will align to that. Everything will align to that.

Yeah, I'm not sure if the laws will align though, because right now think about where did a lot of training data came from? The argument that you're making is when Uber came to India in a lot of cities, they were saying, no, no, let's figure out a way to keep the taxi drivers employed. And they were trying to figure out all these ways on making Uber worse so that the taxi company stays uncompetitive. That's one way to go about it. But eventually you'll realize that that's a futile effort, because if there is a possibility of something more awesome.

Like our tendency is to go towards that. But I think the analogy breaks down in this way because like Uber for its existence does not depend on taxi companies. Whereas like these AI models for their very existence depend on individual like content creators. That's another good topic that we can discuss. Yeah. These models right now, as I understand them, they require a huge amount of data. Yeah. We humans don't.

(20:55.407)
Yeah. Right? Like that's, like this question's coming from like the evolution that we discussed, that like once we hit a wall with our machine learning based solutions, the way we found the next breakthrough was to emulate the way humans worked or human mind works. If you take that analogy further, or if you take that solutioning further, then like we don't require a lot of training data. Like if you had to compress that into like bytes. We can understand like concepts. Yeah. If you tell me a concept,

I can understand it with very little data. Whereas a model needs like tons of examples. So, I mean, it's not far fetched to think that the next evolution would be a massive reduction in the training data required to get the same or better output quality. It's possible. Yeah. So my original question remains is like, is this like a winner takes all type deal where it's futile for...

like the dream of solo, that's why I said solo production. I'm not saying. So I think actually this is a good point to distinguish like what are the different, we're talking about entrepreneurial opportunities in the market space, right? Like let's define the different market segments here. So there's on the one hand, I think classically right now, VCs and people are dividing this into three or four market segments. There's hardware, that's the base layer, Nvidia. Right.

Google with its TPUs and... Yeah, they're providing the hardware layer. That's number one. Number two is foundation models. That's like the large language models. OpenAI is the main player right now, but like Google, Meta and other companies are getting into that space. So that's two layers. The third layer is the application layer. We're like building on top of the foundation models. Like you're building specific applications.

I actually don't know if there's a fourth layer or not. That's the thing, the application layer. I feel like the foundational model layers are gonna consume the application layer. And the reason I worry about that, even though I'm not a solo entrepreneur, I don't have any product, but I've seen this happen. And this has been a big complaint against big tech companies, right? Without getting into the specifics, a lot of times people will develop extensions for browsers or some app which consume.

(23:15.023)
Facebook APIs or like Snapchat APIs. And then eventually what happens is Facebook just creates that product themselves removes API access or let's say it doesn't even remove it. But Facebook is not at the model layer, right? That's the application layer. Yeah, I'm saying the model itself will generalize so much. But it's fundamentally not possible unless the model can have access to Facebook or Google's data. No, no, no. In this analogy of like the model.

your application is some specific use case that uses the model and then enables that use case. I'm saying the model itself will become so powerful and so generalized that you don't need the application layer. But I need specific data. We talked about access to knowledge, external knowledge and data, right? It needs access to my... That's just one use case and that can be solved with plugins. Why would that enable any more business use cases than, hey, like this language model? Yeah, actually, the plugins question is...

more complicated, like why would if I am saying, I work for Facebook, right? I work for Meta. So I, my company owns WhatsApp. Why would WhatsApp release a plugin for OpenAI? That doesn't make any sense. Why would Facebook want to give OpenAI access to like all WhatsApp? Why would Facebook want to give OpenAI access to an entrepreneur? Like, like I'm here, we're talking about like the business opportunities, right?

I don't think this will ever happen. I don't think Meta is ever going to make a plugin for OpenAI. I just don't see it. No, no, I understand that. But I'm saying with that same logic, Meta would also not expose that API to any solopreneur or entrepreneur who wants to create a business. No, that already exists. There's WhatsApp for business. There's a WhatsApp business API. You can use it to create automated messaging. You can create a store. Right.

You can do a lot. You can, yeah. Like WhatsApp is used to run. Let's stick with that example. Let's say there's this API. Yeah. And I use Meta's LLM. Like in the future, let's say Meta comes with their own chat, GPD, LLM. Yeah. And then I build some application. What's to stop Meta from making the LLM so generalized that eliminates the need of this particular application. That's my problem. Like what is the particular application you have in mind? Whatever it is. Like I'm saying eventually these, these.

(25:36.719)
the prompting to chapgpd will be so generalized that they itself will act as an everything application. But it will be multimodal. Here's the thing, like it'll be multimodal. So your input will be multimodal, meaning it could be like text or image or whatever, and the output will be multimodal. And when you have multimodal input and multimodal output, all you need to do is just generalize the application layer. And then with text, I can say, here's what I want with this input, and here's the output.

I think it will ultimately come down to like what data sources and applications you can plug into and integrate with. Like I think that will be a big differentiator. I don't think GPT will like there's open AI, there's Google, Microsoft, Facebook. They all control different applications and I don't think - Yeah, these will still be the players. I'm not saying I'm like these will go away. What I'm saying is like my original question was like as you and I.

Let's say we want to explore some business ideas over here. And it's not just like, hey, let's create something and hope that we'll get acquired or like aqua -hired or whatever. Let's create something durable, enduring. I want to devote the next 25 years of my life. But the way I'm thinking about this is eventually whatever I do will be generalized within those foundational models. There are...

But I guess like what I'm saying is if the thing you're doing requires access to some specific knowledge base, like that is not something that can be absorbed in a foundation. In that case, it will be... No, no, no, I know what you mean. But I'm saying in that case, let's... Like where is this knowledge base? Yeah, I understand. So let's say I build a company that uses some special knowledge base and I obviously want customers, right? And my customers will actually have the special knowledge base. It's not that I hold out. I'm saying...

What stops these LLMs to create like a general interface? Like, hey, as a customer, you going through this, cut the middleman out. that is Chad GPT plugins. Exactly. That's what I'm saying. Like the way I see these things evolving, your Chad GPT plugins and auto GPT. I am thinking that the need like increasingly I see the tech world going into a direction where it's cutting the middleman from everywhere. Like it's famously described as your take rate is my...

(27:50.703)
opportunity. Like what that means is like Amazon say that, Hey, looks like, Hey, you were selling something. You're paying the retailers 25 % margin. That take rate is my opportunity. I'll sell it for 2 .5 % margin. So I'm going to like cut the margin by like the, that might take rate by an order of magnitude. I'll just take 10 % of your existing retailers take and come to my website. So I'm saying that.

Like if you just generalize it and like take it further, it sounds like everything's going to a direction where there'll be one prompt, multimodal prompt. Here's what I need. Here's my data. Here's the output I need. And that like the foundational model will do that. Like I said, I've been grappling with that cause ever since like we've been discussing this for a while, like we just happened to have this discussion in depth today, but I've been thinking about this for a long time and I'm like, I have this fascinating, like Monica had this fascinating idea. It's like,

I'm going to come up with this AI stylist who's going to do this and that. I see it working really well now, but I'll always be living in this existential fear that, this... Because I can't build the foundational models that empower this business. What is to sob these foundational models, just generalize it to a point where they just consume my business?

Because I think like your business is based on a knowledge of your specific customers, their requirements, their workflows, which the foundational models are like, I understand language in general. And you're trying to specify that and come up with a very specific application to a niche use case. So I, yeah, I don't think that will be disrupted. What's a good analogy to this? Like, it's like, that's like saying like, because cloud,

computing providers exist, application layers will become irrelevant. That's not true. Yeah, it's different this time. I know you can't always use that, but I think it's different because the thing that we're dealing with has an agency, has intelligence. I'm using words that you used in our discussion. Yeah. What's the goal of AI? Let's go back to absolute basics to delegate human intelligence to these systems. What is the most evolved product that we discussed today?

(30:01.391)
has a sense of agency. This hugging GPT jargon. Now you combine those two, dude. There's a system that has a sense of agency, has unparalleled human intelligence. But the thing is, there are a bunch of models out here that it's using. These are commoditized. Yeah, open source. These are available open source. Yeah, but the open source versions may not be good, and you need some close. It's going to design its own. But there's proprietary data.

Like I think that's the thing that comes down to. I understand. That's what I'm saying. The ultimate customer will have a very simple way in submitting their proprietary data. And the model for that is plugins. Like you explained it to me and I understood what it means like plugins. But I think different types of proprietary data need different types of plugins. And like the type. You generalize that even like multimodal plugins. I'm not sure. But what is the task ultimately that you want to do? Each task requires a different type of

That's what I'm saying, like stuff like agent GPT or auto GPT comes in. Like I have a multimodal plugin where I'm like, I need this done. And the auto GPT will figure out like, okay, I need to like, let's take the basic example of mathematics and calculator. I want to multiply 1000 into 1644, right? Like I can't do this right now, but it'll figure out that it's a mathematical problem.

and hear all the tools that I need. And maybe there's an opportunity to develop these sub APIs, but I'm saying like, what is to stop it from writing those APIs even calling more agents? One of the ideas that I've been exploring, which is like, I want to help people write their resumes. Okay. Let's talk about that. Yeah. Let's talk about specific examples. Someone has a resume and they want to improve it. And I have been thinking about like, Hey, can I generate like an AI based agent that can help someone improve their resume?

So how would that be genericized? Like what I want to do is take someone's resume, help them understand like what are the weak points in their resume and help them develop that. And right now, like if we put it through this hugging GPT system, it might find some open source models that can do things like find your suitability to a particular job or like your like skills suitability or whatever, but maybe there are better specific models to do that.

(32:23.055)
maybe for specific domains, I could have specific data that helps with that. Like if you are applying for resumes in product management, like maybe I have a database of product management resumes that I could use to specifically optimize that. So yeah, in that context, maybe can you help me understand like what your fear is from a foundation? Like I don't at all see open AI. In the short term, maybe not. I agree with you. In the short term, yes. But if I extrapolate like the advancements that are happening in this technology, I didn't.

exponential scale, then your business is competing with like this exponentially increasing intelligence and whatever you're going to bring, like fine tuning the algorithm. Can you keep up with this thing that like has gone from figuring out home prices and oranges and apples to like, like this, this thing. So I think there's always going to be like the

general version and the specific version. And I think the foundational... Can I challenge that premise? Is there always going to be... Yeah, possibly. Is there always going to be... I don't know. Like, you're most likely right. Yeah. I think there's a very good chance that you are right. Yeah. It's just... I want to... I actually want to prove myself wrong. Like this fear that I have. I think there will always be a need to fine tune the generic version to a specific version.

Like I don't think it's possible that you can say I've come up with the generic version of something that is like absolutely fine tuned to any specific use case. Like, cause if I say I want to write a resume, I want to write a college application, I want to write an email to my friend. These are all like specific applications. So it's possible what you're saying though, that like maybe some generic intelligence. And that's AGI, artificial general intelligence. Like this.

And the MVP in the way you describe it in your product manager world, like a minimum viable product, already exists. Yeah, Chad GPT. No, auto GPT, like this thing. Like this is the MVP to an AGI. That's insane. Yeah, there is an MVP right now. We're in 2023 and the MVP for AGI already exists. And it's Jarvis or hugging. Yeah, like and they're naming it like Jarvis and making it sound cute and like Iron Man, whatever. But the thing is it already exists.

(34:40.367)
So if you take that exponential scale, like this thing's going to get smart. But I take your point. So you're saying one area of exploration for a lot of entrepreneurs could be like this fine tuning. Let's define it by a simple word, fine tuning. Specific domain knowledge. Fine tuning actually has a specific meaning within the language model world. So I wouldn't use that, but I would say like application to domain specific application. Yeah. Yeah. Okay.

Yeah, let's hope that that's the case. Domain knowledge, yeah. Because otherwise, because if, and I can think of other competitive modes that you can have. Like this seems like a good one. I hope that remains. Because if that goes away. Yeah, knowledge of like process, pain points, like, I don't know, the classic like entrepreneur stuff. I'll explain. Maybe I want to explain it better. Like what's my worry? Ever since you told me about the subscription of chat GPD, where you can use the chat GPD four model.

It's insane. I've been so, I've not been as impressed by technology since internet. Like I remember like 20 years back when I first discovered internet, that's how I felt about it. And that's like the feeling that I'm getting now. And it's super smart. And if this is in 2023, then like I, like I've also started thinking about this, like from my daughter's point of view, like, right? Like when she's 18, this tech, what would be the, the level at which this technology would be? So like maybe hopefully in the next 18 years,

it will still be the case that fine tuning or like finding your domain knowledge and processes will still define your competitive mode. I have a fear that it might not, because you're competing with something which is exponentially increasing its intelligence, human intelligence. And this is what people are saying. Like there are people that are very worried about this and they're saying this is AGI and this is going to put all humans out of their jobs and we have to have universal basic income and there's no more jobs for humans to do. Like...

All of this is possible. Like, yeah, I don't know. I don't have a... Yeah, I think this is a very good place to end this discussion. We don't know. I think that, no, this is the perfect place. We don't know. Yeah. Who knows? But as of now, in the month of April in 2023, this is where things stand. Is it April or May? okay. It's still April. Yeah, it's still April. We're heading towards May. Dude, thank you so much for this fascinating conversation. I am so glad we did this. Yeah, I really enjoyed this conversation. Yeah, like this is great. Like we're sitting in...

(37:03.73)
like outside in California. This is one of the longest conversations I've ever had. Yeah, but it's so much fun and so glad we did it. Yeah. I hope whoever is watching, if they ever watch, enjoys this.







# S2E0
## Transcript
Piyush (00:00)
Hey, Neku. Dude, I'm so happy we're doing this.

Nikhil Maddirala (00:01)
Happy Ush!

Yeah, me too.

Piyush (00:06)
Okay, so what is it we're doing exactly? Last year, exactly almost a year back, we recorded a three -hour podcast. Essentially, it was a masterclass on AI by you to me. I've been involved with AI. My job is to basically sell AI, so I've been very curious about AI. But something big happened over the last two years with the launch of ChatGPT and LLMs and whatnot. And it seemed like the whole world was talking about these things.

and I had no clue what these things were, but I was very fascinated by them. So I invited you to basically teach me exactly like what is the magic behind all of these technologies. And you did such a good job in doing so. Actually, it's had a profound impact on me personally and also professionally. So you know this, but like, I feel like my career has kind of been on a rocket ship ever since we did that episode. And I attribute a lot of my career success to actually that three hour conversation that we had.

It's because I told you, right, like I sell AI. So having a very deep understanding of how these technologies work has helped me like shape my like my own understanding. So like, first of all, thank you so much for doing that and like helping me. But it's not just me, like professionally that has gained a lot. Like I've been reached out by so many people who have shared this podcast with their like, this was so amazing. Like, when are you guys doing like episode two or something like, aren't you guys going to follow up? I've actually watched our episode some four or five times.

like I don't stretch already. And I feel like it's such a great foundation to like how AI works. So I agree with those people that I think we should be doing a follow -up. And this is exactly that. I don't know what this will turn out to be, but like I'm just excited that we're following up and we're going to talk more about AI. So thank you so much, Du. Like I'm so grateful that you're taking out time from your busy schedule and basically like helping me learn more about AI. So thank you.

Nikhil Maddirala (02:01)
Okay. I mean, you're embarrassing me. That was obviously, I'm very happy to hear that. Happy to hear that you got a lot out of it and so many other people did as well. And yeah, maybe I can talk a little bit more about my motivation, about why I'm doing this podcast again. so the first thing is I love learning. I love learning new things. That's something I've always been passionate about throughout my life. ever since I was a little kid.

Piyush (02:17)
for sure.

Nikhil Maddirala (02:26)
I was always asking the question why. And when I was a little kid, my family had a nickname for me. It was endoku master, which in Telugu translates in English to the master of the question why, because I was always asking why. And that's something that I've carried with me throughout my life. I love learning and I love helping other people learn. And AI is something specifically that I've been learning about in different ways for over 10 years now. When I first started,

As an undergraduate student, I was studying philosophy and math and logic. And then I went on to get a master's degree in logic. And that was really the early days of AI. And we didn't really conceptualize it in that way, but that's essentially what we were trying to do. We were trying to formalize how human beings think, reason, and speak, communicate with each other, and codify that into a formal logical symbolism, which we thought ultimately could be used to...

teach computers and AI how to think and reason like a human. Of course, that program kind of failed and what took off instead was the machine learning approach, but it's something I've always been curious about. And then I think when I went to business school later, I started taking some coursework in computer science and machine learning. And that led to me doing another master's program in computer science. And I have been really fascinated with AI specifically.

throughout my whole educational journey. Also professionally, I work as an AI product manager. Currently I'm at Meta, prior to that I was at Adobe. At both of these places I've built and scaled AI products that are serving billions of users and millions of businesses. And prior to that I started my career as a consultant with Deloitte where I was also advising Fortune 500 companies on...

things like AI strategy and implementation. Although at that time we didn't call it AI, we called it something like analytics strategy or big data strategy. But essentially what we were doing was the early days of AI strategy. So I have a good amount of educational and professional experience in this field and it's something I'm really passionate about. And I'd love to share my experience, thoughts and perspectives with you and whoever else might benefit from this.

Piyush (04:44)
Yeah, you have an amazing experience. I think you're being too humble about your experience. I don't know how many people realize this. It's both of us work in an industry. So I'm kind of privy to the impact that you had. But I think people ought to know the impact that you had. So here's the story that people ought to know. Let me start with the fact, do you know the biggest stock valuation drop in one day in the history of the world? What that is, I guess, I think you know.

Nikhil Maddirala (04:51)
Thank you.

Piyush (05:14)
It was META. February 2022, in one single day, META lost $230 billion in value, like in one single day. That is insane. And that's the historical record. I don't think any company will ever beat that. It's not a record that anyone would be proud of beating as well. Right. Why did that happen? I don't know if most people understand why would a company lose so much value in one day?

Nikhil Maddirala (05:15)
Yeah, I thought you were just asking the audience.

Piyush (05:43)
in the earnings call Mark Zuckerberg actually said that they're projected to lose $10 billion in annual revenue because of one single change that Apple made. Well, not one single change, but like the pattern of changes that Apple were making. I don't want to get too much into the weeds, but it has something to do with like the way they do tracking. Again, I don't know if most people realize, but Meta makes almost entirety of its revenue from advertising. The problem with the changes that Apple made is...

Meta was losing the ability to do tracking and measurement of these ads properly. So it was losing a lot of signal. So Mark Zuckerberg decided, in the industry it's called signal loss. So Mark Zuckerberg decided to hire the best AI people in the world to figure out how do we work in the world of signal loss. And you, sir, are one of those best people in the world. And the result of hiring such smart people.

Nikhil Maddirala (06:18)
call it signal loss.

Piyush (06:36)
Meta right now has, I think, four or five X their stock value since that stock drop. And it's done amazingly well. Look, I work for Google. And in the industry, people think of Google and Meta as competitors. And sure, they are in some sense. But I admire what Meta does. I admire what you guys have done. And I have deep respect for what you guys have done. So I think you can give yourself a little bit more credit on the amazing thing that you guys have, like you and your team. But I know the kind of work that you have done. So I think it's amazing people ought to know.

That, of course, like based on your educational background and your personal professional background, you have deep expertise in this thing. But a lot of people have deep expertise in AI. You know, the reason why I enjoyed our conversation so much and a lot of people have given me feedback and they enjoyed that conversation so much is I think you also possess another remarkable ability, which is so rare, but amazing, which is you have this knack of explaining insanely complex topics in a very simple and approachable manner.

I think that so like the things that you were explaining to me, I reflect when I watch these episodes again, it's like it was so complex. But the way you made it approachable for me and a lot of other people, I think that's remarkable. So I'm so excited that I have you who was my best friend who knows so much about this and like is like helping me learn about these things. And it sounds like you're also learning more about these things. And this is helpful to you as well. So, yeah, Nick, you.

Nikhil Maddirala (07:59)
Well, I hope I can live up to these high expectations that you've set here. Very flattered. Also want to say credit at Meta goes to a large team of people who are, I'm a drop in the ocean there. And that's one of the humbling experiences of working at a place like this is everyone is just so smart and talented. Yeah. And obviously the amazing engineers that I work with every day just want to give credit where credit is due.

Piyush (08:27)
Of course, of course.

Nikhil Maddirala (08:28)
And yeah, I hope we can live up to the expectations of this podcast. Maybe I also just want to add one thing before we move on is about why I like doing this podcast with you. I think you have, just like you said, I have a knack for explaining things well, you have a knack for producing the right explanations from people and especially from me. And that comes from knowing what is the right question to ask, when to ask that question. And.

asking it in such a way that it elicits a good and explanatory answer to the question. And I think you're really great at that. And that's probably what leads you to be so successful in your sales career. And you've actually taken the learnings that you got out of the podcast that we did last year, the first season, and you've lived that. You now understand the power and the capability of AI and exactly how it works. And you've

transformed your role from selling advertising into basically selling an AI solution. And we should talk about this in one of our future podcast episodes, but I think not many people in your world actually understand the implications of what AI means for digital advertising and what that means for how they should allocate their budgets, how they should try to optimize their ad campaigns. And you've really taken all the lessons from AI.

too hard and applied that there. And you're seeing great success for yourself, for all the clients that you advise. So I'm definitely curious to hear a lot more about that in one of our future episodes.

Piyush (10:05)
Yeah, sorry, kind of you meant to say all those things. Well, and I hope that how these conversations have helped me. Like, hopefully what we're producing today will help other people as well. So with that, I know you've had a lot of time to think about what this podcast should be called and what we should do in the podcast. Do you have any insights to share? Like, we're calling it the art and science of AI. You came up with that name. Help me understand. What were you thinking? What's going on in your mind?

Nikhil Maddirala (10:35)
So one is just a personal passion of mine. I think combining the arts and sciences leads to things of great beauty. This is something that people like Steve Jobs always talked about. He always wanted technology to be co -created by artists and scientists. And he always wanted people with an artistic background, a humanities background, together with scientific and engineering minds to come together to create a great product.

And I think AI is very much like that. AI is the new era of technology that we're in right now. And there's a science to it and there's an art to it. The science of AI is a lot of what we covered in the first season of this podcast. The fundamentals of how machine learning models are trained, what data they use, how they're optimized, what are the functions used to optimize them and parameters and tokens and all of that. That's the science of AI.

Piyush (11:30)
but nuts and bolts.

Nikhil Maddirala (11:32)
Yeah, the nuts and bolts and we talked about that. But there's also an, I mean, that's, I would say 80 % signs even there, there's like 20 % art often is trial and error. You don't know what, what are the right hyper parameters to set? What's the right architecture? People play around with these things and they come up with new innovations, but that that's 80 % signs. But then when you take this AI application or model that's out there and think about.

how to start using that to solve problems that you're facing in your everyday life or in your business, that's pretty much still an art. And I don't think that will ever be a science that very much like how entrepreneurship is an art. So the art of being able to identify problems, being able to map that onto solutions that AI can provide for you and being able to.

customize the solution to your particular needs and make sure you're solving your challenges. I think that that's really an art. And also in terms of building AI applications, knowing how a user is going to interact with it, what the user wants out of this experience, understanding the user's psychology and needs. A lot of things which I think companies today still haven't figured out and getting it wrong. So there's a huge art to it. So...

I think this podcast is about the science of understanding how AI works and about the art of how AI is transforming business and society.

Piyush (13:00)
That's cool. Actually, now that you're speaking about it, I'm thinking, does that mean that this podcast is only useful for people who are working with AI or are in an industry that deals with AI? Because it's obviously helpful for me, and I am one of those people who works in this space. In fact, I spend a lot of intimate time with AI, selling AI. But are there others who would stand to benefit by listening to this podcast?

Nikhil Maddirala (13:27)
I think it's beneficial for everyone to learn about AI today. AI is going to be everywhere and in everything. So think back to in 2011, I think Mark Andreessen wrote about how software is eating the world. Mark Andreessen, obviously one of the famous venture capitalists in the Valley, he's the inventor of the first ever browser, Netscape. He talked about back in 2011,

how software is eating the world. And by that, he meant that every business, every industry is going to become a software business or a software industry. And you see that today already over, and it's taken about 10 to 15 years for this transformation to occur. I was very surprised recently, I was at a conference a couple of years ago and CEOs from companies like Visa and other like non -technical companies or companies they would think of as not tech companies.

They want to say that I'm leading a tech company. My company is a tech company. And I think everyone has realized that today. Think about like the taxi industry. You would have thought, well, what does the taxi have to do with technology? But ultimately taxi companies now are tech companies, groceries, restaurants. What does that have to do with technology? But every company today has to implement some kind of like technology to not only manage their own operations.

Piyush (14:37)
Hmm that's a good one

Nikhil Maddirala (14:51)
but also to interact with customers because that's how customers want to interact with them. If a restaurant doesn't have a way for me to easily make a reservation online or look up their information online, I'm less likely to go there. So that's what Mark Andreessen was talking about 15 years ago. Software is eating the world. So at that time, probably a lot of people said, I don't need to know about technology. I don't need to know about software. I work in the grocery industry. I work in the taxi industry. I do something that's unrelated to technology, but that obviously was not true.

And now everything is based on technology. So I think now we're at a similar transformation where AI is going to be eating the world and everything is going to have AI incorporated into it soon. And you might think, so industries we've been working in like tech, ads, they've had AI built in for a long time now, but now for the first time industries that...

Piyush (15:43)
Right.

Nikhil Maddirala (15:47)
were never really interested or had a need for AI or having to build in AI into their products and services just to become more efficient or even to meet customers where they're at. Like in the past, companies had to build say websites and mobile applications to enable customers to interact with them. But now in future, suppose customers get used to a world in which they use AI assistance to interact with everything.

businesses are going to be forced to transform from their web and mobile presence into some kind of AI based presence. And I think similarly, even at the backend, the way they manage their operations and everything, you know, we went through two transformations. First, it was from a non tech world to a tech world. And now it's from a tech world to an AI powered tech world. So I really think in 10 years or how long did it take Mark Andreessen or this?

Piyush (16:21)
Hmm.

Nikhil Maddirala (16:42)
15 years ago. So definitely, I think 15 years from now, it's highly likely that we'll look back and think it's really silly that people thought AI would not affect their life or their business in some way.

Piyush (16:56)
That's a very insightful perspective. Yeah. I think that Uber example that you gave, that's a remarkable example. You're right. Who would have in their right mind thought, like, imagine if you're like a New York taxi cab driver, like, did you ever think that you would be disrupted by tech? No, right? But these things happen. So I imagine in a similar fashion.

Nikhil Maddirala (17:10)
No, yeah. Same travel industry, there's Airbnb, how tech companies are disrupting travel for so many products and services today. And if you see any company today or any industry where technology is not a major component, that is ripe for disruption. And you have a good entrepreneurship opportunity right there. At least I think so.

Piyush (17:15)
Right.

Right. So what you're saying essentially is the same thing might be repeating or is very likely to repeat in the context of AI. There might be someone who's like, I don't need an AI strategy. Like, I don't know. I'm thinking off the top of my head. Maybe Trader Joe's is thinking like, no, I sell cucumbers and chicken shawarma. I don't need an AI strategy. But perhaps AI might disrupt your business. So everyone needs to be thinking about this.

Nikhil Maddirala (17:55)
So there will be some outliers like how today there are some companies that still don't really incorporate technology too much. I think Trader Joe's is one example. They don't have an app where I can look at their inventory or order online or anything because maybe it doesn't make sense for their business model. But they probably still use a lot of technology internally to do things like inventory management, predicting, stocking requirements. They have to know exactly how many...

Piyush (18:15)
Right.

Nikhil Maddirala (18:22)
apples do I have to ship to this store today such that the apples don't go bad at the end of the day, but also like customers have enough apples to buy. And that's actually a pretty hard problem. And I'd be surprised if they're not already using AI in some way to solve that problem.

Piyush (18:32)
Right.

Right, right. Now that's I mean, I'm sold. I think everyone needs to be thinking about these things. So I'm super excited to to like learn more about this and like kind of continue our conversation from last time. So maybe we'll just dive into it. What do you say?

Nikhil Maddirala (18:54)
Yeah, so let's jump in and see everyone in the next episode.

Piyush (19:01)
Sounds good. All right.

