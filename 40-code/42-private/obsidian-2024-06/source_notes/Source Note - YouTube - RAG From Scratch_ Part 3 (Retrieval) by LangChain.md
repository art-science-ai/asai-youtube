---
source-title: RAG From Scratch: Part 3 (Retrieval)
source-url: https://youtube.com/watch?v=LxNVgdIz9sU

source-mediatype: video
source-platform: YouTube

source-youtube-video-id: LxNVgdIz9sU
source-youtube-channel-id: UCC-lyoTfSrcJzA1ab3APAgw
source-youtube-channel-name: LangChain
---

## Summary (AI)
**TLDR:**
The video discusses the process of retrieval in the context of building a retrieval-augmented generation (RAG) system from scratch. It explains how documents are indexed, retrieved, and used to generate answers based on the retrieved documents. Retrieval involves embedding documents and questions into a high-dimensional space, performing a similarity search, and retrieving relevant documents. The speaker provides a code walkthrough demonstrating how to implement this retrieval process using KNN (k-nearest neighbors) search.

**Key Points:**
- The video focuses on retrieval in the context of building a retrieval-augmented generation (RAG) system.
- Retrieval involves indexing documents, embedding them into a high-dimensional space, performing a similarity search, and retrieving relevant documents.
- Documents are split and embedded into numerical representations for easy searchability and storage in an index.
- A similarity search is conducted based on the embeddings of both the documents and the question.
- Documents with similar semantics to the question are retrieved as they reside in close proximity in the embedding space.
- The selection of K (number of nearby neighbors) in the retrieval process influences the number of relevant documents retrieved.
- The speaker provides a code walkthrough demonstrating how to implement KNN search for document retrieval using a few lines of code.
- The retrieval process is demonstrated by querying a question and retrieving relevant documents based on the specified K value.
- The approach highlights the ease of implementing KNN search for retrieval using this method.

## Video description
Error retrieving description for video LxNVgdIz9sU

## Video transcript
hi this is Lance from Lang chain and this is the third video in our series rag from scratch building up a lot of the motivations for rag uh from the very basic components um so we're going to be talking about retrieval today in the last two uh short videos I outlined indexing and gave kind of an overview of this flow which starts with indexing of our documents retrieval of documents relevant to our question and then generation of anwers based on the retriev documents and so we saw that the indexing process basically makes documents easy to retrieve and it goes through a flow that basically looks like you take our documents you split them in some way into these smaller chunks that can be easily embedded um those embeddings are then numerical representations of those documents that are easily searchable and they're stored in an index when given a question that's also embedded the index performs a similarity search and returns splits that are relevant to the question now if we dig a little bit more under the hood we can think about it like this if we take a document and embed it let's imagine that embedding just had three dimensions so you know each document is projected into some point in this 3D space now the point is that the location in space is determined by the semantic meaning or content in that document so to follow that then documents in similar locations in space contain similar semantic information and this very simple idea is really the Cornerstone for a lot of search and retrieval methods that you'll see with modern Vector stores so in particular we take our documents we embed them into this in this case a toy 3D space we take our question do the same we can then do a search like a local neighborhood search you can think about in this 3D space around our question to say hey what documents are nearby and these nearby neighbors are then retrieved because they can they have similar semantics relative to our question and that's really what's going on here so again we took our documents we split them we embed them and now they exist in this high-dimensional space we've taken our question embedded it projected in that same space and we just do a search around the question for nearby documents and grab ones that are close and we can pick some number we can say we want one or two or three or n documents close to my question in this embedding space and there's a lot of really interesting methods that implement this very effectively I I link one here um and we have a lot of really nice uh Integrations to play with this general idea so many different embedding models many different indexes lots of document loaders um and lots of Splitters that can be kind of recombined to test different ways of doing this kind of indexing or retrieval um so now I'll show a bit of a Code walkthrough so here we defined um we kind of had walked through this previously this is our notebook we've installed a few packages we've set a few environment variables using lsmith and we showed this previously this is just an overview showing how to run rag like kind of end to end in the last uh short talk we went through inding um and what I'm going to do very simply is I'm just going to reload our documents so now I have our documents I'm going to resplit them and we saw before how we can build our index now here let's actually do the same thing but in the slides we actually showed kind of that notion of search in that 3D space and a nice parameter to think about in building your your retriever is K so K tells you the number of nearby neighbors to fetch when you do that retrieval process and we talked about you know in that 3D space do I want one nearby neighbor or two or three so here we can specify k equals one for example now we're building our index so we're taking every split embedding it storing it now what's nice is I ask a question what is Task decomposition this is related to the blog post and I'm going to run get relevant documents so I run that and now how many documents do I get back I get one as expected based upon k equals 1 so this retrieve document should be related to my question now I can go to Langs Smith and we can open it up and we can look at our Retriever and we can see here was our question here's the one document we got back and okay so that makes sense this document pertains to task decomposition in particular and it kind of lays out a number of different approaches that can be used to do that this all kind of makes sense and this shows kind of in practice how you can implement this this NE this kind of KNN or k nearest neighbor search uh really easily uh just using a few lines of code and next we're going to talk about generation thanks
