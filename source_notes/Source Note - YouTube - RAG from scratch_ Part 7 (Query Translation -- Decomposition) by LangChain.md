---
source-title: RAG from scratch: Part 7 (Query Translation -- Decomposition)
source-url: https://youtube.com/watch?v=h0OPWlEOank

source-mediatype: video
source-platform: YouTube

source-youtube-video-id: h0OPWlEOank
source-youtube-channel-id: UCC-lyoTfSrcJzA1ab3APAgw
source-youtube-channel-name: LangChain
---

## Summary (AI)
TLDR: The video discusses query translation in the context of decomposing input questions to improve retrieval. The speaker explains techniques like breaking down questions into subproblems, solving them sequentially, and combining retrieval with Chain of Thought reasoning. A demonstration using code shows how decomposed questions lead to better answers compared to answering questions independently.

Key Points:
- Query translation involves modifying or decomposing input questions to enhance retrieval in the rag Pipeline.
- Techniques like breaking down questions into subproblems and sequentially solving them are explored.
- Combining retrieval with Chain of Thought reasoning, as in the IRC approach, allows for dynamic retrieval to solve a set of subproblems.
- The video demonstrates using code to decompose questions into subproblems and iteratively solve them, leveraging prior question answers for better results.
- Another approach involves answering questions independently and then concatenating their answers, which might be suitable for cases where questions are independent of each other.
- By employing query decomposition techniques, insights from different papers can be utilized effectively to improve question answering processes.

## Video description
Error retrieving description for video h0OPWlEOank

## Video transcript
hi this is Lance from Lang chain this is our third video focused on query translation in the rag from scratch series and we're going to be talking about decomposition so quer translation in general is a set of approaches that sits kind of towards the front of this overall rag Pipeline and the objective is to modify or rewrite or otherwise decompose and input question from a user in order to improve retrieval so we kind of talked through some of these approaches previously in particular various ways to do query writing like rag fusion and multi-query there's a separate set of techniques that become pretty popular and are really interesting for certain problems which we might call like breaking down or decomposing an input question and set up sub questions um so some of the papers here that are are pretty cool are for example this work from Google um and the objective really is first to take an input question and decompose it into a set of sub problems so this particular example from the paper was the problem of um last letter concatenation and so it took the imput question of three words think machine learning and broke it down into three sub problems think think machine think machine learning as the third sub problem and then you can see in this bottom panel it solves each one individually so it shows for example in green solving the problem think machine where you can catenate the last letter of k with the last letter of machine or last letter of think K lesser machine e concatenate those to K and then for the overall problem taking that solution and then and basically building on it to get the overall solution of keg so that's kind of one concept of decomposing into sub problems solving them sequentially now a related work called IRC or inter leap retrieval combines retrieval with Chain of Thought reasoning and so you can kind of put these together into one approach which you can think of as kind of dynamically retrieval um to solve a set of sub problems kind of that retrieval kind of interleaving with Chain of Thought as noted in the second paper and a set of decomposed questions based on your initial question from the first work from Google so really the idea here is we're taking one sub question we're answering it we're taking that answer and using it to help answer the second sub question and so forth so let's actually just walk through this in code to show how this might work so this is The Notebook we've been working with from some of the other uh videos you can see we already have a retriever defined uh up here at the top and what we're going to do is we're first going to find a prompt that's basically going to say give given an input question let's break it down to a set of sub problems or sub question which can be solved individually so we can do that and this blog post is focused on agents so let's ask a question about what are the main components of an LM powered autonomous agent system so let's run this and see what the decomposed questions are so you can see the decomposed questions are what is LM technology how does it work um what are speciic components and then how the compos inter so it's kind of a sane way to kind of break down this problem into a few sub problems which you might attack individually now here's where um we Define a prompt that very simply is going to take our question we'll take any prior questions we've answered and we'll take our retrieval and basically just combine them and we can Define this very simple chain um actually let's go back and make sure retriever is defined up at the top so now we are building our retriever good we have that now so we can go back down here and let's run this so now we are running and what's happening is we're trying to solve each of these questions individually using retrieval and using any prior question answers so okay very good looks like that's been done and we can see here's our answer now let's go over to Lang see what happened under the hood so here's what's kind of interesting and helpful to see for the first question so here's our first one it looks like it just does retrieval which is we expect and then it uses that to answer this initial question now for the second question should be a little bit more interesting because if you look at our prompt here's our question now here is our background available question answer pair so this was the answer question answer pair from the first question which we add to our prompt and then here's the retrieval for this particular question so we're kind of building up the solution because we're pending the question answer pair from question one and then likewise with question three it should combine all of that so we can look at here here's our question here's question one here's question two great now here's additional retrieval related to this particular question and we get our final answer so that's like a really nice way you can kind of build up Solutions um using this kind of inter leave uh retrieval and concatenating prior question answer pairs I do want to mention very briefly that we can also take a different approach where we can just answer these all individually and then just concatenate all those answers to produce a final answer and I'll show that really quickly here um it's like a little bit less interesting maybe because you're not using answers from each uh question to inform the next one you're just answering them all in parallel this might be better for cases where it's it's not really like a sub question decomposition but maybe it's like a set of set of several in independent questions whose answers don't depend on each other that might be relevant for some problems um and we can go ahead and run okay so this ran as well we can look at our trace and in this case um yeah we can see that this actually just kind of concatenates all of our QA pairs to produce the final answer so this gives you sense for how you can use Query decomposition employ ideas from uh from two different papers that are pretty cool thanks
