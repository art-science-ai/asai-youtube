---
source-title: RAG from scratch: Part 6 (Query Translation -- RAG Fusion)
source-url: https://youtube.com/watch?v=77qELPbNgxA

source-mediatype: video
source-platform: YouTube

source-youtube-video-id: 77qELPbNgxA
source-youtube-channel-id: UCC-lyoTfSrcJzA1ab3APAgw
source-youtube-channel-name: LangChain
---

## Summary (AI)
TLDR: The video is the second part of a series on query translation in the context of advanced RAG (Retrieval Augmented Generation) pipelines, focusing on an approach called RAG Fusion. The method involves breaking down a user question into multiple perspectives, retrieving documents based on these perspectives, and using reciprocal rank Fusion to consolidate and rank the retrieved documents for final output. This approach is showcased using code examples in a notebook.

Key points:
- Query translation is crucial in advanced RAG pipelines for improving retrieval of relevant information.
- Different approaches to query translation include rewriting, sub-questions, and stepping back to abstract levels.
- RAG Fusion, a form of rewriting, involves breaking a question into differently worded queries, retrieving documents for each query, and consolidating rankings using reciprocal rank Fusion.
- Reciprocal rank Fusion helps in building a consolidated ranking across multiple retrievals, which is beneficial for generating a final answer.
- The process involves running retrievals, ranking the documents, generating multiple search queries, and presenting the final list of ranked documents.
- The method can be useful for handling retrieval across various scenarios and can be customized by adjusting the number of top documents to consider.

## Video description
Error retrieving description for video 77qELPbNgxA

## Video transcript
hi this is L liting chain this is the second video of our deep dive on query translation in our rag from scratch series focused on a method called rag Fusion so as we kind of showed before quer translation you can think of as at the first stage in an advanced rag pipeline we're taking an input user question and We're translating in some way in order to prove retrieval now we showed this General mapping of approaches previously so again you have kind of like rewriting so you can take a question and like kind of break it down into uh differently worded or different different perspectives of the same question so that's kind of rewriting there's sub questions where you take a question break it down into smaller problems solve each one independently and then there's step back where you take a question and kind of go more abstract where you kind of ask a higher level question as a precondition to answer the user question so those are the approaches and we're going to dig into one of the particular approaches for rewriting called rat Fusion now this is really similar to what we just saw with multiquery the difference being we actually apply a a kind of a clever rank ranking step of our retrieve documents um which you call reciprocal rank Fusion that's really the only difference the the input stage of taking a question breaking it out into a few kind of differently worded questions retrieval on each one is all the same and we're going to see that in the code here shortly so let's just hop over there and then look at this so again here is a notebook that we introduced previously here's the packages we've installed we've set a few API keys for lsmith which see why is quite useful um and you can kind of go down here to our rag Fusion section and the first thing you'll note is what our prompt is so it looks really similar to The Prompt we just saw with multiquery and simply your helpful assistant that generates multiple search queries based upon user input and here's the question output for queries so let's define our prompt and here was our queer Generation chain again this looks a lot like we just saw we take our prompt Plum that into an llm and then basically parse by new lines and that'll basically split out these questions into a list that's all going to happen here so that's cool now here's where the novelty comes in each time we do retrieval from one of those questions we're going to get back a list of documents from our Retriever and so we do it over that we generate four questions here based on our prompt we do the four questions well like a list of lists basically now reciprocal rank Fusion is really well suited for this exact problem we want to take this list to list and build a single Consolidated list and really all that's going on is it's looking at the documents in each list and kind of aggregating them into a final output ranking um and that's really the intuition around what's happening here um so let's go ahead and so let's so let's go ahead and look at that in some detail so we can see we run retrieval that's great now let's go over to Langs Smith and have a look at what's going on here so we can see that here is our prompt your helpful assistant that generates multiple search queries based on single input and here is our search queries and then here are our four retrievals so that's that's really really good so we know that all is working um and then those retrievals simply went into this rank function and are correspondingly ranked to a final list of six unique rank documents that's really all we did so let's actually put that all together into an full rag chain that's going to run retrieval return that final list of rank documents and pass it to our context pass through our question send that to our rag prompt pass it to an LM parse it to an output and let's run all that together and see that working cool so there's our final answer now let's have a look in lsmith we can see here was our four questions here's our retrievals and then our final rag prompt plump through the final list of ranked six questions which we can see laid out here and our final answer so this can be really convenient particularly if we're operating across like maybe different Vector stores uh or we wanted do like retrieval across a large number of of kind of differently worded questions this reciprocal rank Fusion step is really nice um for example if we wanted to only take the top three documents or something um it can be really nice to build that Consolidated ranking across all these independent retrievals then pass that to the LM for the final generation so that's really the intuition about what's happening here thanks
